{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7bcdb7",
   "metadata": {},
   "source": [
    "# Phase 4 (Revised): Dark-Cycle Estrous Discovery (Vehicle Cages Only)\n",
    "## Morph2REP Study 1001 (2025v3.3) — cycle-aware inference from Envision video-derived behavior\n",
    "\n",
    "### What we’re trying to do\n",
    "We **do not have estrous ground-truth labels** (no vaginal cytology).  \n",
    "Our goal is to test whether we can recover a **within-mouse ~4–5 day cyclic signal** consistent with estrous using **home-cage, video-derived behavioral bouts**.\n",
    "\n",
    "### Why dark-cycle focus?\n",
    "In home-cage data, light-cycle behavior is often constrained and can reduce variance. Estrous-linked modulation frequently appears as changes in:\n",
    "- locomotion/exploration intensity\n",
    "- sleep / inactivity structure\n",
    "- fragmentation of bouts\n",
    "\n",
    "We therefore compute features **per “night”** (6 PM → 6 AM EST), which spans two calendar dates.\n",
    "\n",
    "### Strategy\n",
    "1. Load **vehicle-only cages** using the same DuckDB → S3 `read_parquet` approach as Phase 3.\n",
    "2. Apply **data cleaning** (spillover, cage change, termination days).\n",
    "3. Build **dark-cycle nightly features** per mouse.\n",
    "4. Normalize **within mouse**:\n",
    "   - raw nightly metrics\n",
    "   - within-mouse z-scores\n",
    "   - leakage-safe rolling z-scores (past-only baseline)\n",
    "5. Dimensionality reduction (PCA).\n",
    "6. Fit a **4-state time-aware model** (HMM) to infer latent “phase-like” states.\n",
    "7. Validate with:\n",
    "   - per-mouse periodicity near 4–5 days (Lomb–Scargle on PC1)\n",
    "   - dwell times & transition matrix sanity checks\n",
    "\n",
    "### Data available (used here)\n",
    "- `animal_bouts.parquet`: bout start/end times, state name, bout duration seconds\n",
    "- `animal_bout_metrics.parquet` (optional): bout-level metrics such as distance by state (schema varies)\n",
    "\n",
    "> This notebook is designed to be robust to `animal_bout_metrics.parquet` schema differences by attempting to detect the correct metric columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c9546",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Setup: packages and imports\n",
    "We install and import packages for:\n",
    "- loading parquet from S3: DuckDB + PyArrow\n",
    "- feature engineering: pandas/numpy\n",
    "- modeling: scikit-learn + hmmlearn\n",
    "- periodicity: SciPy Lomb–Scargle\n",
    "- plotting: matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd011a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install duckdb pyarrow pandas numpy scikit-learn scipy matplotlib hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66287125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.signal import lombscargle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5b4e8",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Configuration: vehicle cages, dates, and exclusions (data cleaning)\n",
    "We follow your study metadata and keep **vehicle cages only**:\n",
    "\n",
    "- Rep 1 vehicle cages: 4918, 4922, 4923  \n",
    "- Rep 2 vehicle cages: 4928, 4929, 4934\n",
    "\n",
    "### Cleaning rules (from your Phase 3 cleaning table)\n",
    "We exclude:\n",
    "- acclimation spillover days: **Jan 9** (Rep1), **Jan 24** (Rep2)\n",
    "- cage change days: **Jan 15** (Rep1), **Jan 29** (Rep2)\n",
    "- termination/unstable days: **Feb 3–4** (Rep2)\n",
    "\n",
    "### Time alignment\n",
    "Facility schedule is **EST**:\n",
    "- Lights ON 6:00 AM EST\n",
    "- Lights OFF 6:00 PM EST\n",
    "\n",
    "Timestamps are stored as **UTC**. EST = UTC − 5 hours, so:\n",
    "- 6:00 AM EST = 11:00 UTC\n",
    "- 6:00 PM EST = 23:00 UTC\n",
    "\n",
    "**Dark cycle = outside [11:00, 23:00) UTC**, i.e., `hour < 11` OR `hour >= 23`.\n",
    "We assign each bout to a **night_date**:\n",
    "- 6 PM–midnight: night_date = same calendar day (UTC date)\n",
    "- midnight–6 AM: belongs to **previous night_date** (subtract 1 day when hour < 11 UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "S3_BASE = \"s3://jax-envision-public-data/study_1001/2025v3.3/tabular\"\n",
    "\n",
    "VEHICLE_CAGES = {\n",
    "    \"Rep1\": {\n",
    "        \"cages\": [4918, 4922, 4923],\n",
    "        \"analysis_start\": \"2025-01-10\",  # after acclimation (Jan 7–9)\n",
    "        \"analysis_end\": \"2025-01-22\",\n",
    "        \"cage_change\": date(2025, 1, 15),\n",
    "    },\n",
    "    \"Rep2\": {\n",
    "        \"cages\": [4928, 4929, 4934],\n",
    "        \"analysis_start\": \"2025-01-25\",  # after acclimation (Jan 22–24)\n",
    "        \"analysis_end\": \"2025-02-04\",\n",
    "        \"cage_change\": date(2025, 1, 29),\n",
    "    },\n",
    "}\n",
    "\n",
    "EXCLUDE_DATES = {\n",
    "    \"Rep1\": {date(2025, 1, 9), date(2025, 1, 15)},\n",
    "    \"Rep2\": {date(2025, 1, 24), date(2025, 1, 29), date(2025, 2, 3), date(2025, 2, 4)},\n",
    "}\n",
    "\n",
    "LIGHT_START_UTC = 11  # 6 AM EST\n",
    "LIGHT_END_UTC = 23    # 6 PM EST\n",
    "\n",
    "print(\"Vehicle cages & cleaning:\")\n",
    "for rep, cfg in VEHICLE_CAGES.items():\n",
    "    print(f\"- {rep}: cages={cfg['cages']}, window={cfg['analysis_start']}..{cfg['analysis_end']}, exclude={sorted(EXCLUDE_DATES[rep])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad0caf",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) Loading utilities (DuckDB → parquet on S3)\n",
    "We load the same tables you used previously via DuckDB `read_parquet` from S3 partitions:\n",
    "- `animal_bouts.parquet`\n",
    "- `animal_bout_metrics.parquet`\n",
    "\n",
    "We only pull partitions for the cages + cleaned dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026643fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(start: str, end: str) -> List[date]:\n",
    "    start_d = datetime.strptime(start, \"%Y-%m-%d\").date()\n",
    "    end_d = datetime.strptime(end, \"%Y-%m-%d\").date()\n",
    "    out = []\n",
    "    d = start_d\n",
    "    while d <= end_d:\n",
    "        out.append(d)\n",
    "        d += timedelta(days=1)\n",
    "    return out\n",
    "\n",
    "def load_table_for_cages_dates(table_name: str, cages: List[int], dates: List[date]) -> pd.DataFrame:\n",
    "    conn = duckdb.connect(database=\":memory:\")\n",
    "    all_data = []\n",
    "    for cage_id in cages:\n",
    "        for d in dates:\n",
    "            date_str = d.strftime(\"%Y-%m-%d\")\n",
    "            path = f\"{S3_BASE}/cage_id={cage_id}/date={date_str}/{table_name}\"\n",
    "            try:\n",
    "                df = conn.execute(f\"SELECT * FROM read_parquet('{path}')\").fetchdf()\n",
    "                df[\"cage_id\"] = cage_id\n",
    "                df[\"date\"] = date_str\n",
    "                all_data.append(df)\n",
    "            except Exception:\n",
    "                continue\n",
    "    conn.close()\n",
    "    if not all_data:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "TABLE_BOUTS = \"animal_bouts.parquet\"\n",
    "TABLE_BOUT_METRICS = \"animal_bout_metrics.parquet\"\n",
    "\n",
    "def load_vehicle_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    all_bouts = []\n",
    "    all_metrics = []\n",
    "    for rep, cfg in VEHICLE_CAGES.items():\n",
    "        cages = cfg[\"cages\"]\n",
    "        days = date_range(cfg[\"analysis_start\"], cfg[\"analysis_end\"])\n",
    "        # cleaning: remove cage change and explicit exclusions\n",
    "        days = [d for d in days if d != cfg[\"cage_change\"]]\n",
    "        days = [d for d in days if d not in EXCLUDE_DATES[rep]]\n",
    "\n",
    "        df_b = load_table_for_cages_dates(TABLE_BOUTS, cages, days)\n",
    "        df_m = load_table_for_cages_dates(TABLE_BOUT_METRICS, cages, days)\n",
    "\n",
    "        if not df_b.empty:\n",
    "            df_b[\"replicate\"] = rep\n",
    "            all_bouts.append(df_b)\n",
    "        if not df_m.empty:\n",
    "            df_m[\"replicate\"] = rep\n",
    "            all_metrics.append(df_m)\n",
    "\n",
    "    bouts = pd.concat(all_bouts, ignore_index=True) if all_bouts else pd.DataFrame()\n",
    "    metrics = pd.concat(all_metrics, ignore_index=True) if all_metrics else pd.DataFrame()\n",
    "    return bouts, metrics\n",
    "\n",
    "df_bouts, df_metrics = load_vehicle_data()\n",
    "print(\"Loaded:\")\n",
    "print(\"  bouts rows:\", len(df_bouts))\n",
    "print(\"  metrics rows:\", len(df_metrics))\n",
    "print(\"\\nBouts columns:\", df_bouts.columns.tolist())\n",
    "print(\"\\nMetrics columns:\", df_metrics.columns.tolist()[:40], \"...\" if len(df_metrics.columns)>40 else \"\")\n",
    "df_bouts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161c1b9",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Feature engineering: Dark-cycle nightly features (fixed + robust)\n",
    "This is the *fixed* version of your `compute_dark_cycle_features`:\n",
    "\n",
    "### Fixes applied\n",
    "✅ **Timezone correctness:** `pd.to_datetime(..., utc=True)` so `hour_utc` is truly UTC.  \n",
    "✅ **Night assignment correctness:** bouts with `hour_utc < 11` belong to the previous night.  \n",
    "✅ **Metrics correctness:** we only sum distance-like metrics *if we can identify them* from schema; otherwise we skip distance features safely.  \n",
    "✅ **State handling:** works whether `state_name` is full (e.g., `animal_bouts.active`) or short (e.g., `active`).\n",
    "\n",
    "### Outputs\n",
    "One row per `(cage_id, animal_id, night_date)` with:\n",
    "- per-state duration / count / mean bout length\n",
    "- derived composites (physically_demanding, sleep_related, feeding_resourcing, activity_amplitude, fragmentation, exploration_intensity if distance is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46faf57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_utc(ts: pd.Series) -> pd.Series:\n",
    "    # Force UTC to avoid ambiguous 'hour_utc' extraction\n",
    "    return pd.to_datetime(ts, utc=True, errors=\"coerce\")\n",
    "\n",
    "def _is_dark_hour(hour_utc: pd.Series) -> pd.Series:\n",
    "    return ~((hour_utc >= LIGHT_START_UTC) & (hour_utc < LIGHT_END_UTC))\n",
    "\n",
    "def _night_date_from_start(ts_utc: pd.Series) -> pd.Series:\n",
    "    ts = _parse_utc(ts_utc)\n",
    "    hour = ts.dt.hour\n",
    "    night = ts.dt.date\n",
    "    # before 11:00 UTC belongs to previous night (6am EST boundary)\n",
    "    mask = hour < LIGHT_START_UTC\n",
    "    night = pd.Series(night, index=ts.index)\n",
    "    night.loc[mask] = (ts.loc[mask] - pd.Timedelta(days=1)).dt.date\n",
    "    return night\n",
    "\n",
    "def _normalize_state_name(s: pd.Series) -> pd.Series:\n",
    "    # Map 'animal_bouts.active' -> 'active', also handle already-short names\n",
    "    s = s.astype(str)\n",
    "    return s.str.split(\".\").str[-1].str.lower()\n",
    "\n",
    "def _detect_metric_columns(df_m: pd.DataFrame) -> Tuple[Optional[str], Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Try to infer:\n",
    "    - time column: start_time or time or timestamp\n",
    "    - metric name column: metric_name or name\n",
    "    - metric value column: metric_value or value\n",
    "    Returns (time_col, name_col, value_col)\n",
    "    \"\"\"\n",
    "    cols = {c.lower(): c for c in df_m.columns}\n",
    "    time_col = None\n",
    "    for cand in [\"start_time\", \"time\", \"timestamp\", \"time_stamp\"]:\n",
    "        if cand in cols:\n",
    "            time_col = cols[cand]\n",
    "            break\n",
    "    name_col = None\n",
    "    for cand in [\"metric_name\", \"name\"]:\n",
    "        if cand in cols:\n",
    "            name_col = cols[cand]\n",
    "            break\n",
    "    value_col = None\n",
    "    for cand in [\"metric_value\", \"value\"]:\n",
    "        if cand in cols:\n",
    "            value_col = cols[cand]\n",
    "            break\n",
    "    return time_col, name_col, value_col\n",
    "\n",
    "def compute_dark_cycle_features_fixed(df_bouts: pd.DataFrame, df_metrics: pd.DataFrame) -> pd.DataFrame:\n",
    "    # --------- BOUTS ---------\n",
    "    df_b = df_bouts.copy()\n",
    "    # Robust timestamp parse\n",
    "    df_b[\"start_time\"] = _parse_utc(df_b[\"start_time\"])\n",
    "    df_b = df_b.dropna(subset=[\"start_time\", \"animal_id\", \"state_name\", \"bout_length_seconds\"])\n",
    "    df_b[\"hour_utc\"] = df_b[\"start_time\"].dt.hour\n",
    "    df_b[\"is_dark\"] = _is_dark_hour(df_b[\"hour_utc\"])\n",
    "    df_b = df_b[df_b[\"is_dark\"]].copy()\n",
    "\n",
    "    df_b[\"night_date\"] = _night_date_from_start(df_b[\"start_time\"])\n",
    "    df_b[\"state_short\"] = _normalize_state_name(df_b[\"state_name\"])\n",
    "\n",
    "    # Aggregate per state\n",
    "    grp = df_b.groupby([\"cage_id\", \"animal_id\", \"night_date\", \"state_short\"])\n",
    "    agg = grp[\"bout_length_seconds\"].agg([\"sum\", \"count\", \"mean\"]).reset_index()\n",
    "    agg = agg.rename(columns={\"sum\": \"duration_s\", \"count\": \"bout_count\", \"mean\": \"mean_bout_s\"})\n",
    "\n",
    "    # Pivot wide\n",
    "    def pivot_value(val_col: str, suffix: str) -> pd.DataFrame:\n",
    "        wide = agg.pivot_table(index=[\"cage_id\", \"animal_id\", \"night_date\"], columns=\"state_short\", values=val_col, aggfunc=\"first\")\n",
    "        wide.columns = [f\"{c}_{suffix}\" for c in wide.columns]\n",
    "        return wide.reset_index()\n",
    "\n",
    "    dur = pivot_value(\"duration_s\", \"duration\")\n",
    "    cnt = pivot_value(\"bout_count\", \"bout_count\")\n",
    "    mb  = pivot_value(\"mean_bout_s\", \"mean_bout\")\n",
    "\n",
    "    df_summary = dur.merge(cnt, on=[\"cage_id\",\"animal_id\",\"night_date\"], how=\"outer\").merge(mb, on=[\"cage_id\",\"animal_id\",\"night_date\"], how=\"outer\")\n",
    "\n",
    "    # Total duration (dark bouts)\n",
    "    total = df_b.groupby([\"cage_id\",\"animal_id\",\"night_date\"])[\"bout_length_seconds\"].sum().reset_index().rename(columns={\"bout_length_seconds\":\"total_duration\"})\n",
    "    df_summary = df_summary.merge(total, on=[\"cage_id\",\"animal_id\",\"night_date\"], how=\"left\")\n",
    "\n",
    "    # Fill NaNs for duration/count/mean features with 0 (state absent that night)\n",
    "    for c in df_summary.columns:\n",
    "        if c.endswith((\"_duration\",\"_bout_count\",\"_mean_bout\")) or c in [\"total_duration\"]:\n",
    "            df_summary[c] = df_summary[c].fillna(0.0)\n",
    "\n",
    "    # --------- METRICS (distance-like) ---------\n",
    "    if df_metrics is not None and len(df_metrics) > 0:\n",
    "        df_m = df_metrics.copy()\n",
    "        time_col, name_col, value_col = _detect_metric_columns(df_m)\n",
    "\n",
    "        if time_col is not None and value_col is not None:\n",
    "            df_m[time_col] = _parse_utc(df_m[time_col])\n",
    "            df_m = df_m.dropna(subset=[time_col, value_col])\n",
    "            df_m[\"hour_utc\"] = df_m[time_col].dt.hour\n",
    "            df_m[\"is_dark\"] = _is_dark_hour(df_m[\"hour_utc\"])\n",
    "            df_m = df_m[df_m[\"is_dark\"]].copy()\n",
    "            df_m[\"night_date\"] = _night_date_from_start(df_m[time_col])\n",
    "\n",
    "            # Determine which rows correspond to distance.\n",
    "            # If we have a metric-name column, filter by 'distance' keyword.\n",
    "            if name_col is not None:\n",
    "                name_series = df_m[name_col].astype(str).str.lower()\n",
    "                dist_mask = name_series.str.contains(\"distance|dist|path_length|displacement\", regex=True, na=False)\n",
    "                df_m_dist = df_m[dist_mask].copy()\n",
    "            else:\n",
    "                # No metric name column; cannot safely interpret as distance\n",
    "                df_m_dist = pd.DataFrame()\n",
    "\n",
    "            # If there is a state column, normalize it for per-state distance; else only compute total distance\n",
    "            state_col = None\n",
    "            for cand in [\"state_name\", \"state\", \"behavior_state\"]:\n",
    "                if cand in {c.lower(): c for c in df_m.columns}:\n",
    "                    state_col = {c.lower(): c for c in df_m.columns}[cand]\n",
    "                    break\n",
    "\n",
    "            if len(df_m_dist) > 0:\n",
    "                df_m_dist[value_col] = pd.to_numeric(df_m_dist[value_col], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "                dist_total = df_m_dist.groupby([\"cage_id\",\"animal_id\",\"night_date\"])[value_col].sum().reset_index().rename(columns={value_col:\"total_distance\"})\n",
    "                df_summary = df_summary.merge(dist_total, on=[\"cage_id\",\"animal_id\",\"night_date\"], how=\"left\")\n",
    "\n",
    "                if state_col is not None:\n",
    "                    df_m_dist[\"state_short\"] = _normalize_state_name(df_m_dist[state_col])\n",
    "                    dist_state = df_m_dist.groupby([\"cage_id\",\"animal_id\",\"night_date\",\"state_short\"])[value_col].sum().reset_index()\n",
    "                    dist_state = dist_state.pivot_table(index=[\"cage_id\",\"animal_id\",\"night_date\"], columns=\"state_short\", values=value_col, aggfunc=\"first\")\n",
    "                    dist_state.columns = [f\"{c}_distance\" for c in dist_state.columns]\n",
    "                    dist_state = dist_state.reset_index()\n",
    "                    df_summary = df_summary.merge(dist_state, on=[\"cage_id\",\"animal_id\",\"night_date\"], how=\"left\")\n",
    "\n",
    "                # Fill missing distances with 0\n",
    "                for c in df_summary.columns:\n",
    "                    if c.endswith(\"_distance\") or c == \"total_distance\":\n",
    "                        df_summary[c] = df_summary[c].fillna(0.0)\n",
    "            else:\n",
    "                # No distance rows found; skip\n",
    "                pass\n",
    "\n",
    "    # --------- DERIVED FEATURES (Khatiz-style composites) ---------\n",
    "    # Make sure required base columns exist (if state absent, column might be missing; create as 0)\n",
    "    def ensure(col):\n",
    "        if col not in df_summary.columns:\n",
    "            df_summary[col] = 0.0\n",
    "\n",
    "    for base in [\"locomotion_duration\", \"climbing_duration\", \"inferred_sleep_duration\", \"feeding_duration\", \"drinking_duration\", \"active_duration\"]:\n",
    "        ensure(base)\n",
    "    for base in [\"inferred_sleep_bout_count\", \"active_bout_count\"]:\n",
    "        ensure(base)\n",
    "\n",
    "    df_summary[\"physically_demanding\"] = df_summary[\"locomotion_duration\"] + df_summary[\"climbing_duration\"]\n",
    "    df_summary[\"sleep_related\"] = df_summary[\"inferred_sleep_duration\"]\n",
    "    df_summary[\"feeding_resourcing\"] = df_summary[\"feeding_duration\"] + df_summary[\"drinking_duration\"]\n",
    "    df_summary[\"activity_amplitude\"] = df_summary[\"active_duration\"] + df_summary[\"locomotion_duration\"]\n",
    "\n",
    "    df_summary[\"sleep_fragmentation\"] = df_summary[\"inferred_sleep_bout_count\"] / (df_summary[\"inferred_sleep_duration\"] + 1.0)\n",
    "    df_summary[\"active_fragmentation\"] = df_summary[\"active_bout_count\"] / (df_summary[\"active_duration\"] + 1.0)\n",
    "\n",
    "    if \"total_distance\" in df_summary.columns:\n",
    "        df_summary[\"exploration_intensity\"] = df_summary[\"total_distance\"] / (df_summary[\"activity_amplitude\"] + 1.0)\n",
    "\n",
    "    # Sort for downstream rolling operations\n",
    "    df_summary[\"night_date\"] = pd.to_datetime(df_summary[\"night_date\"])\n",
    "    df_summary = df_summary.sort_values([\"animal_id\",\"night_date\"])\n",
    "\n",
    "    return df_summary\n",
    "\n",
    "nightly = compute_dark_cycle_features_fixed(df_bouts, df_metrics)\n",
    "print(\"Nightly feature table:\", nightly.shape)\n",
    "nightly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7cf10d",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) Within-mouse normalization (nightly)\n",
    "Estrous is a **within-mouse** cycle, so we create:\n",
    "- raw nightly features (for reference)\n",
    "- within-mouse z-scores across nights\n",
    "- leakage-safe rolling z-scores using only past nights\n",
    "\n",
    "We will model on within-mouse z by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature columns\n",
    "key_cols = [\"cage_id\", \"animal_id\", \"night_date\"]\n",
    "feature_cols = [c for c in nightly.columns if c not in key_cols]\n",
    "\n",
    "# Ensure numeric for feature cols\n",
    "for c in feature_cols:\n",
    "    nightly[c] = pd.to_numeric(nightly[c], errors=\"coerce\")\n",
    "\n",
    "# Simple within-mouse z-score\n",
    "df_within = nightly.copy()\n",
    "for c in feature_cols:\n",
    "    df_within[c] = df_within.groupby(\"animal_id\")[c].transform(lambda s: (s - s.mean()) / (s.std(ddof=0) + 1e-8))\n",
    "\n",
    "# Rolling z-score using past only (no leakage)\n",
    "df_roll = nightly.copy()\n",
    "WINDOW = 5\n",
    "MINP = 3\n",
    "for c in feature_cols:\n",
    "    g = df_roll.groupby(\"animal_id\")[c]\n",
    "    mu = g.shift(1).rolling(window=WINDOW, min_periods=MINP).mean()\n",
    "    sd = g.shift(1).rolling(window=WINDOW, min_periods=MINP).std(ddof=0)\n",
    "    df_roll[c] = (df_roll[c] - mu) / (sd + 1e-8)\n",
    "\n",
    "display(nightly.head(3))\n",
    "display(df_within.head(3))\n",
    "display(df_roll.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6474683f",
   "metadata": {},
   "source": [
    "---\n",
    "## 6) Build model matrix + PCA\n",
    "We:\n",
    "1) choose a normalized table (within-mouse z by default)\n",
    "2) impute missing values (median)\n",
    "3) standardize features\n",
    "4) run PCA and keep enough PCs to explain ~85% variance (capped at 10 PCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285197c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DF = df_within.copy()  # swap to df_roll if you want leakage-safe baseline in modeling\n",
    "\n",
    "X = MODEL_DF[feature_cols].copy()\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imp = imputer.fit_transform(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imp)\n",
    "\n",
    "pca = PCA(n_components=min(10, X_scaled.shape[1]))\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained = np.cumsum(pca.explained_variance_ratio_)\n",
    "k = int(np.searchsorted(explained, 0.85) + 1)\n",
    "k = max(2, min(k, X_pca.shape[1]))\n",
    "X_pca_k = X_pca[:, :k]\n",
    "\n",
    "print(\"X_scaled:\", X_scaled.shape, \"X_pca_k:\", X_pca_k.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, len(explained)+1), explained, marker=\"o\")\n",
    "plt.xlabel(\"Number of PCs\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\"PCA explained variance (nightly, vehicle)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b424d70",
   "metadata": {},
   "source": [
    "---\n",
    "## 7) Fit a 4-state HMM and decode nightly states\n",
    "We use a Gaussian HMM (hmmlearn). This is time-aware and discourages rapid switching.\n",
    "\n",
    "- 4 states is a natural starting point for estrous-like phase structure.\n",
    "- We initialize with a “sticky” transition matrix (high self-transition) to reduce noise-driven flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73735acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = None\n",
    "post = None\n",
    "\n",
    "try:\n",
    "    from hmmlearn.hmm import GaussianHMM\n",
    "    hmm_ok = True\n",
    "except Exception as e:\n",
    "    hmm_ok = False\n",
    "    print(\"Could not import hmmlearn:\", e)\n",
    "\n",
    "if hmm_ok:\n",
    "    n_states = 4\n",
    "    model = GaussianHMM(\n",
    "        n_components=n_states,\n",
    "        covariance_type=\"full\",\n",
    "        n_iter=250,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # sticky initialization\n",
    "    transmat = np.full((n_states, n_states), 0.05 / (n_states - 1))\n",
    "    np.fill_diagonal(transmat, 0.95)\n",
    "    model.transmat_ = transmat\n",
    "    model.startprob_ = np.full(n_states, 1.0 / n_states)\n",
    "\n",
    "    model.fit(X_pca_k)\n",
    "    states = model.predict(X_pca_k)\n",
    "    post = model.predict_proba(X_pca_k)\n",
    "\n",
    "    print(\"Learned transition matrix:\")\n",
    "    display(pd.DataFrame(model.transmat_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30c57a",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Results table (mouse-night) + quick visualization\n",
    "We attach:\n",
    "- inferred state (0..3)\n",
    "- max posterior confidence\n",
    "- PC1 (for periodicity tests)\n",
    "\n",
    "Then we plot a heatmap: mice x nights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fed9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = MODEL_DF[[\"cage_id\", \"animal_id\", \"night_date\"]].copy()\n",
    "results[\"night_date\"] = pd.to_datetime(results[\"night_date\"]).dt.date\n",
    "\n",
    "results[\"PC1\"] = X_pca_k[:, 0]\n",
    "if states is not None:\n",
    "    results[\"state\"] = states\n",
    "    results[\"state_conf\"] = post.max(axis=1)\n",
    "else:\n",
    "    results[\"state\"] = np.nan\n",
    "    results[\"state_conf\"] = np.nan\n",
    "\n",
    "# Heatmap\n",
    "pivot = results.pivot_table(index=\"animal_id\", columns=\"night_date\", values=\"state\", aggfunc=\"first\").sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, max(4, 0.15 * len(pivot))))\n",
    "plt.imshow(pivot.values, aspect=\"auto\", interpolation=\"nearest\")\n",
    "plt.yticks(np.arange(len(pivot.index)), pivot.index)\n",
    "plt.xticks(np.arange(len(pivot.columns)), [d.strftime(\"%m-%d\") for d in pivot.columns], rotation=90)\n",
    "plt.colorbar(label=\"Inferred state\")\n",
    "plt.title(\"Inferred 4-state sequence per mouse-night (vehicle, dark cycle)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a6add",
   "metadata": {},
   "source": [
    "---\n",
    "## 9) Validation: per-mouse periodicity near 4–5 days (Lomb–Scargle on PC1)\n",
    "We test for a strong period in the 2.5–8 day range and summarize the best period per mouse.\n",
    "If estrous-like modulation exists, we expect many mice to show a peak around ~4–5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lomb_best_period(t_days, y, min_period=2.5, max_period=8.0, n_freq=600):\n",
    "    t = np.asarray(t_days, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    m = np.isfinite(t) & np.isfinite(y)\n",
    "    t, y = t[m], y[m]\n",
    "    if len(t) < 6:\n",
    "        return np.nan\n",
    "    periods = np.linspace(min_period, max_period, n_freq)\n",
    "    freqs = 2 * np.pi / periods\n",
    "    y0 = y - y.mean()\n",
    "    pgram = lombscargle(t, y0, freqs, normalize=True)\n",
    "    return float(periods[int(np.argmax(pgram))])\n",
    "\n",
    "peaks = []\n",
    "for aid, g in results.groupby(\"animal_id\"):\n",
    "    g = g.sort_values(\"night_date\")\n",
    "    t0 = pd.to_datetime(g[\"night_date\"]).min()\n",
    "    t_days = (pd.to_datetime(g[\"night_date\"]) - t0).dt.days.values\n",
    "    peaks.append((aid, lomb_best_period(t_days, g[\"PC1\"].values)))\n",
    "\n",
    "peak_df = pd.DataFrame(peaks, columns=[\"animal_id\", \"best_period_days\"]).dropna()\n",
    "display(peak_df.describe())\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(peak_df[\"best_period_days\"].values, bins=20)\n",
    "plt.xlabel(\"Best period (days)\")\n",
    "plt.ylabel(\"Count of mice\")\n",
    "plt.title(\"Distribution of best Lomb–Scargle periods (PC1, vehicle, dark)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e95cdf",
   "metadata": {},
   "source": [
    "---\n",
    "## 10) Validation: dwell times + transition matrix sanity checks\n",
    "Estrous-like states should not jump randomly. We compute:\n",
    "- empirical transition matrix from decoded sequences\n",
    "- dwell time distribution per state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sorted = results.sort_values([\"animal_id\", \"night_date\"])\n",
    "trans_counts = np.zeros((4,4), dtype=int)\n",
    "dwell = {s: [] for s in range(4)}\n",
    "\n",
    "for aid, g in res_sorted.groupby(\"animal_id\"):\n",
    "    seq = g[\"state\"].dropna().astype(int).values\n",
    "    if len(seq) < 2:\n",
    "        continue\n",
    "    for a, b in zip(seq[:-1], seq[1:]):\n",
    "        trans_counts[a, b] += 1\n",
    "\n",
    "    # run-length encoding for dwell\n",
    "    cur = seq[0]; run = 1\n",
    "    for x in seq[1:]:\n",
    "        if x == cur:\n",
    "            run += 1\n",
    "        else:\n",
    "            dwell[cur].append(run)\n",
    "            cur = x; run = 1\n",
    "    dwell[cur].append(run)\n",
    "\n",
    "trans_prob = trans_counts / np.maximum(trans_counts.sum(axis=1, keepdims=True), 1)\n",
    "display(pd.DataFrame(trans_prob))\n",
    "\n",
    "print(\"Mean dwell length (nights) per state:\")\n",
    "for s in range(4):\n",
    "    vals = dwell[s]\n",
    "    if vals:\n",
    "        print(f\"state {s}: mean={np.mean(vals):.2f}, n={len(vals)}\")\n",
    "    else:\n",
    "        print(f\"state {s}: no data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91401ae",
   "metadata": {},
   "source": [
    "---\n",
    "## 11) Export\n",
    "We save a CSV of mouse-night inferred states and PC1.\n",
    "You can join this back to other nightly features or use it to search for “cycle day” anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/mnt/data/phase4_vehicle_darkcycle_cycle_states.csv\"\n",
    "results.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d428d60",
   "metadata": {},
   "source": [
    "---\n",
    "## 12) Next steps (recommended)\n",
    "If you see a clear ~4–5 day peak in many mice:\n",
    "\n",
    "1) Add a **null test**:\n",
    "   - shuffle night order within each mouse; the 4–5 day peak should disappear.\n",
    "2) Upgrade HMM to **cyclic-constrained** transitions (P→E→M→D→P).\n",
    "3) Add modalities:\n",
    "   - drinking totals (`animal_drinking`)\n",
    "   - respiration (`animal_respiration` / `animal_tsdb_mvp`)\n",
    "   - sociability (`animal_sociability_pairwise`)\n",
    "These often increase estrous signal-to-noise.\n",
    "\n",
    "If you want, I can extend this notebook to include the null test + cyclic-constrained HMM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

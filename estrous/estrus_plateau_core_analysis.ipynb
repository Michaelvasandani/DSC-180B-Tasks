{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f8c449-9dc0-4a00-8045-31b6caa354fb",
   "metadata": {},
   "source": [
    "# Estrus-Linked Locomotor Plateau Detection  \n",
    "## Morph2REP (Study 1001, Version 2025v3.3)\n",
    "\n",
    "This notebook analyzes estrus-associated locomotor structure in female strain 664 mice\n",
    "from the Morph2REP study (Study 1001, Version 2025v3.3).\n",
    "\n",
    "Replicate 1:\n",
    "- Dates: 2025-01-07 to 2025-01-22\n",
    "- Cages: 4917–4925\n",
    "\n",
    "Replicate 2:\n",
    "- Dates: 2025-01-22 to 2025-02-04\n",
    "- Cages: 4926–4934\n",
    "\n",
    "---\n",
    "\n",
    "## Scientific Motivation\n",
    "\n",
    "Prior work (Smarr et al.) suggests estrus does not increase behavioral noise,\n",
    "but instead introduces structured changes in locomotor activity,\n",
    "specifically a prolonged dark-phase plateau of near-peak activity.\n",
    "\n",
    "This notebook tests whether estrus-linked structure can be detected\n",
    "*without ground-truth staging*, using only behavioral time series.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Analysis Strategy\n",
    "\n",
    "1. Extract per-animal locomotion (60s resolution)\n",
    "2. Define an animal-specific plateau threshold (e.g., 85th percentile)\n",
    "3. Compute plateau duration per day\n",
    "4. Rank days by plateau duration\n",
    "5. Test whether top-k days differ from the rest using permutation testing\n",
    "\n",
    "---\n",
    "\n",
    "## Primary Outputs\n",
    "\n",
    "- Per-animal plateau duration\n",
    "- Per-cage rankings\n",
    "- Per-replicate rankings\n",
    "- Top-k vs rest permutation tests\n",
    "- Statistical significance of estrus-like structure\n",
    "\n",
    "---\n",
    "\n",
    "All timestamps are aligned to the 12h:12h light-dark cycle (6AM–6PM EST lights on).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504dfe0e-564f-4859-9053-b3bd4fc838d8",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Configuration\n",
    "\n",
    "Load Morph2REP locomotor data from animal_activity_db or\n",
    "animal_aggs_short_id at 60-second resolution.\n",
    "\n",
    "Define:\n",
    "- Replicate cages\n",
    "- Time window\n",
    "- Light-dark boundaries\n",
    "- Percentile threshold for plateau detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758011f-24bd-4ca2-81f0-df87ea0c77cf",
   "metadata": {},
   "source": [
    "## 2. Extract Per-Animal Locomotion (60s Resolution)\n",
    "\n",
    "Filter:\n",
    "- name == 'animal_bouts.locomotion'\n",
    "- resolution == 60\n",
    "\n",
    "Compute:\n",
    "- Day index relative to study start\n",
    "- Dark-phase mask (6PM–6AM EST)\n",
    "- Per-animal daily locomotion vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab086c-b0eb-4d7a-b1c5-783a3cf090e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "S3_BASE = \"s3://jax-envision-public-data/study_1001/2025v3.3/tabular\"\n",
    "\n",
    "VEHICLE_CAGES = {\n",
    "    \"Rep1\": {\n",
    "        \"cages\": [4918, 4922, 4923],\n",
    "        \"start\": \"2025-01-10 06:00:00\",\n",
    "        \"end\":   \"2025-01-22 06:00:00\",\n",
    "    },\n",
    "    \"Rep2\": {\n",
    "        \"cages\": [4928, 4929, 4934],\n",
    "        \"start\": \"2025-01-25 06:00:00\",\n",
    "        \"end\":   \"2025-02-04 06:00:00\",\n",
    "    },\n",
    "}\n",
    "\n",
    "MINUTES_PER_DAY = 1440\n",
    "DAYS_PER_CYCLE = 4\n",
    "MINUTES_PER_CYCLE = DAYS_PER_CYCLE * MINUTES_PER_DAY\n",
    "\n",
    "# Dark phase: CT12–24 → minutes 720–1440\n",
    "DARK_START = 720\n",
    "DARK_END = 1440\n",
    "\n",
    "# ============================================================\n",
    "# ROBUST PLATEAU THRESHOLD (fixes outlier-driven max)\n",
    "# Use an upper-quantile threshold on the MEDIAN profile itself.\n",
    "# Example: 85th percentile of the full 4-day median profile.\n",
    "# ============================================================\n",
    "PLATEAU_Q = 85  # try 80–90; 85 is a good default\n",
    "\n",
    "# ============================================================\n",
    "# GLOBAL CACHE (avoid re-loading from S3)\n",
    "# ============================================================\n",
    "ACTIVITY_CACHE = {}\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "def load_activity(cage_id, start, end):\n",
    "    key = (cage_id, start, end)\n",
    "    if key in ACTIVITY_CACHE:\n",
    "        return ACTIVITY_CACHE[key]\n",
    "\n",
    "    conn = duckdb.connect()\n",
    "    conn.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "    conn.execute(\"SET s3_region='us-east-1';\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        time,\n",
    "        animal_id,\n",
    "        value\n",
    "    FROM read_parquet(\n",
    "        '{S3_BASE}/cage_id={cage_id}/date=*/animal_activity_db.parquet'\n",
    "    )\n",
    "    WHERE\n",
    "        name = 'animal_bouts.locomotion'\n",
    "        AND resolution = 60\n",
    "        AND time BETWEEN TIMESTAMP '{start}' AND TIMESTAMP '{end}'\n",
    "    ORDER BY time\n",
    "    \"\"\"\n",
    "\n",
    "    df = conn.execute(query).fetchdf()\n",
    "    conn.close()\n",
    "\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    ACTIVITY_CACHE[key] = df\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# BUILD MEDIAN 4-DAY PROFILE (PER REPLICATE)\n",
    "#   - For each cage: average across animals per timestamp\n",
    "#   - Fold into 4-day cycle: minute_in_cycle\n",
    "#   - Take mean per minute_in_cycle (across all included cycles)\n",
    "#   - Take median across cages\n",
    "# ============================================================\n",
    "def build_median_4day_profile(cfg):\n",
    "    baseline = pd.to_datetime(cfg[\"start\"])\n",
    "    cage_profiles = []\n",
    "\n",
    "    for cage_id in cfg[\"cages\"]:\n",
    "        df = load_activity(cage_id, cfg[\"start\"], cfg[\"end\"])\n",
    "\n",
    "        g = (\n",
    "            df.groupby(\"time\")[\"value\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        minutes = ((g[\"time\"] - baseline).dt.total_seconds() / 60).astype(int)\n",
    "        g[\"minute\"] = minutes\n",
    "\n",
    "        # keep complete 4-day cycles only\n",
    "        g = g[g[\"minute\"] >= 0]\n",
    "        max_full_cycles = (g[\"minute\"].max() + 1) // MINUTES_PER_CYCLE\n",
    "        g = g[g[\"minute\"] < max_full_cycles * MINUTES_PER_CYCLE]\n",
    "\n",
    "        g[\"minute_in_cycle\"] = g[\"minute\"] % MINUTES_PER_CYCLE\n",
    "\n",
    "        cage_profiles.append(\n",
    "            g.groupby(\"minute_in_cycle\")[\"value\"].mean()\n",
    "        )\n",
    "\n",
    "    median_profile = pd.concat(cage_profiles, axis=1).median(axis=1).values\n",
    "    return median_profile\n",
    "\n",
    "# ============================================================\n",
    "# OPTIONAL: Plateau RUN on a 4-day median profile\n",
    "# (longest contiguous run above threshold, with gap tolerance)\n",
    "# ============================================================\n",
    "def longest_run_with_gap(mask: np.ndarray, gap: int = 1) -> int:\n",
    "    best = cur = gap_left = 0\n",
    "    for v in mask:\n",
    "        if v:\n",
    "            cur += 1\n",
    "            gap_left = gap\n",
    "        elif gap_left > 0:\n",
    "            cur += 1\n",
    "            gap_left -= 1\n",
    "        else:\n",
    "            cur = 0\n",
    "            gap_left = gap\n",
    "        best = max(best, cur)\n",
    "    return best\n",
    "\n",
    "# ============================================================\n",
    "# PLATEAU STATISTICS ON MEDIAN PROFILE (ROBUST THRESHOLD)\n",
    "#   - Threshold = percentile(whole 4-day median profile, PLATEAU_Q)\n",
    "#   - Compute per-cycle-day dark-phase plateau duration (minutes)\n",
    "#   - Also compute plateau_run (longest contiguous run, minutes)\n",
    "# ============================================================\n",
    "def plateau_stats_on_median(profile, label, plateau_q=PLATEAU_Q, gap=1):\n",
    "    thresh = float(np.nanpercentile(profile, plateau_q))\n",
    "\n",
    "    results = []\n",
    "    for day in range(DAYS_PER_CYCLE):\n",
    "        start = day * MINUTES_PER_DAY + DARK_START\n",
    "        end = day * MINUTES_PER_DAY + DARK_END\n",
    "\n",
    "        dark = profile[start:end]\n",
    "        above = dark >= thresh\n",
    "\n",
    "        plateau_duration = int(np.sum(above))                 # minutes above threshold\n",
    "        plateau_run = int(longest_run_with_gap(above, gap))   # longest run above threshold (min)\n",
    "\n",
    "        results.append({\n",
    "            \"cycle_day\": day + 1,\n",
    "            \"plateau_duration_min\": plateau_duration,\n",
    "            \"plateau_run_min\": plateau_run\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(results)\n",
    "\n",
    "    # rank days (separately) by duration and by run\n",
    "    out = out.sort_values([\"plateau_run_min\", \"plateau_duration_min\"], ascending=False).reset_index(drop=True)\n",
    "    out[\"rank_by_run_then_duration\"] = np.arange(1, len(out) + 1)\n",
    "\n",
    "    print(f\"\\n=== Plateau ranking for {label} ===\")\n",
    "    print(f\"Threshold = {plateau_q}th percentile of 4-day median profile = {thresh:.4f}\")\n",
    "    print(out.to_string(index=False))\n",
    "\n",
    "    return out, thresh\n",
    "\n",
    "# ============================================================\n",
    "# PLOTTING\n",
    "# ============================================================\n",
    "def plot_median_profile(profile, title, thresh, plateau_q=PLATEAU_Q):\n",
    "    t_hours = np.arange(len(profile)) / 60.0\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.plot(t_hours, profile, linewidth=1.5)\n",
    "    plt.axhline(thresh, color=\"red\", linestyle=\"--\", label=f\"{plateau_q}th percentile threshold\")\n",
    "\n",
    "    # Dark phase shading (CT12–24 each day)\n",
    "    for d in range(DAYS_PER_CYCLE):\n",
    "        plt.axvspan(d * 24 + 12, d * 24 + 24, color=\"black\", alpha=0.10)\n",
    "\n",
    "    plt.xlabel(\"Time (hours across 4-day cycle)\")\n",
    "    plt.ylabel(\"Locomotion (fraction of time)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# RUN FOR REP1 + REP2\n",
    "# ============================================================\n",
    "rep1_median_4day = build_median_4day_profile(VEHICLE_CAGES[\"Rep1\"])\n",
    "rep2_median_4day = build_median_4day_profile(VEHICLE_CAGES[\"Rep2\"])\n",
    "\n",
    "rank_rep1, thresh_rep1 = plateau_stats_on_median(rep1_median_4day, \"JAX Rep1 median 4-day profile\", plateau_q=PLATEAU_Q, gap=1)\n",
    "rank_rep2, thresh_rep2 = plateau_stats_on_median(rep2_median_4day, \"JAX Rep2 median 4-day profile\", plateau_q=PLATEAU_Q, gap=1)\n",
    "\n",
    "plot_median_profile(rep1_median_4day, \"JAX Rep1 – Median 4-Day Profile (Vehicle)\", thresh_rep1, plateau_q=PLATEAU_Q)\n",
    "plot_median_profile(rep2_median_4day, \"JAX Rep2 – Median 4-Day Profile (Vehicle)\", thresh_rep2, plateau_q=PLATEAU_Q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19187df-b3ce-4460-925f-0be072ad43c3",
   "metadata": {},
   "source": [
    "## 3. Plateau Definition, Daily Computation, and Ranking\n",
    "\n",
    "### Step 1: Define Animal-Specific Plateau Threshold\n",
    "\n",
    "For each animal:\n",
    "\n",
    "- Extract all dark-phase locomotion values across the analysis window\n",
    "- Compute the q-th percentile (e.g., 85th percentile)\n",
    "- Define this value as that animal’s plateau threshold\n",
    "\n",
    "Rationale:\n",
    "Using a relative (within-animal) threshold controls for baseline\n",
    "activity differences across animals and focuses on near-peak behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Compute Daily Plateau Duration\n",
    "\n",
    "For each animal and day:\n",
    "\n",
    "Plateau duration =\n",
    "Number of dark-phase minutes where locomotion ≥ threshold\n",
    "\n",
    "This produces:\n",
    "\n",
    "- Per-animal daily plateau duration\n",
    "- A structured table indexed by:\n",
    "  replicate → cage → animal → day\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Rank Days by Estrus-Like Structure\n",
    "\n",
    "Within cage or replicate:\n",
    "\n",
    "- Compute mean plateau duration per day (across animals)\n",
    "- Rank days in descending order\n",
    "\n",
    "Higher rank → stronger estrus-like plateau structure  \n",
    "Top-k days → candidate estrus days\n",
    "\n",
    "This ranking forms the basis for the permutation testing step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5751d-39e0-4f98-ae59-daacba9579f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PLOTTING\n",
    "# ============================================================\n",
    "def plot_median_profile(profile, title, thresh, plateau_q=PLATEAU_Q):\n",
    "    t_hours = np.arange(len(profile)) / 60.0\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.plot(t_hours, profile, linewidth=0.5)\n",
    "    plt.axhline(thresh, color=\"red\", linestyle=\"--\", label=f\"{plateau_q}th percentile threshold\")\n",
    "\n",
    "    # Dark phase shading (CT12–24 each day)\n",
    "    for d in range(DAYS_PER_CYCLE):\n",
    "        plt.axvspan(d * 24 + 12, d * 24 + 24, color=\"black\", alpha=0.10)\n",
    "\n",
    "    plt.xlabel(\"Time (hours across 4-day cycle)\")\n",
    "    plt.ylabel(\"Locomotion (fraction of time)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# RUN FOR REP1 + REP2\n",
    "# ============================================================\n",
    "rep1_median_4day = build_median_4day_profile(VEHICLE_CAGES[\"Rep1\"])\n",
    "rep2_median_4day = build_median_4day_profile(VEHICLE_CAGES[\"Rep2\"])\n",
    "\n",
    "rank_rep1, thresh_rep1 = plateau_stats_on_median(rep1_median_4day, \"JAX Rep1 median 4-day profile\", plateau_q=PLATEAU_Q, gap=1)\n",
    "rank_rep2, thresh_rep2 = plateau_stats_on_median(rep2_median_4day, \"JAX Rep2 median 4-day profile\", plateau_q=PLATEAU_Q, gap=1)\n",
    "\n",
    "plot_median_profile(rep1_median_4day, \"JAX Rep1 – Median 4-Day Profile (Vehicle)\", thresh_rep1, plateau_q=PLATEAU_Q)\n",
    "plot_median_profile(rep2_median_4day, \"JAX Rep2 – Median 4-Day Profile (Vehicle)\", thresh_rep2, plateau_q=PLATEAU_Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626605f-5523-4a1f-99ce-139e92a8a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "MINUTES_PER_DAY = 1440\n",
    "DAYS_PER_CYCLE = 4\n",
    "MINUTES_PER_CYCLE = DAYS_PER_CYCLE * MINUTES_PER_DAY\n",
    "\n",
    "# Dark phase in Smarr convention: first 12h of each day\n",
    "DARK_START = 0\n",
    "DARK_END = 720\n",
    "\n",
    "# Plateau definition: fraction of global max of the median profile\n",
    "PLATEAU_FRAC = 0.80   # 80% of max is robust and matches \"near-peak plateau\"\n",
    "\n",
    "# ============================================================\n",
    "# LOAD SMARR FEMALE DATA (ALIGNED)\n",
    "# ============================================================\n",
    "df_smarr = pd.read_csv(\"mice data.xlsx - FemAct (1).csv\")\n",
    "\n",
    "female_cols = [c for c in df_smarr.columns if str(c).lower().startswith(\"fem\")]\n",
    "if len(female_cols) == 0:\n",
    "    raise ValueError(\"No female columns found (expected columns starting with 'fem').\")\n",
    "\n",
    "female_data = df_smarr[female_cols].to_numpy().T  # (n_females, n_timepoints)\n",
    "n_females, n_timepoints = female_data.shape\n",
    "\n",
    "print(f\"Loaded Smarr data: {n_females} females, {n_timepoints} minutes\")\n",
    "\n",
    "# Only keep complete 4-day cycles\n",
    "n_cycles = n_timepoints // MINUTES_PER_CYCLE\n",
    "if n_cycles < 1:\n",
    "    raise ValueError(\"Not enough data for a complete 4-day cycle.\")\n",
    "\n",
    "female_data = female_data[:, :n_cycles * MINUTES_PER_CYCLE]\n",
    "\n",
    "# ============================================================\n",
    "# BUILD MEDIAN 4-DAY PROFILE (ALIGNED)\n",
    "# ============================================================\n",
    "reshaped = female_data.reshape(\n",
    "    n_females, n_cycles, MINUTES_PER_CYCLE\n",
    ")  # (females, cycles, minutes)\n",
    "\n",
    "median_per_female = np.median(reshaped, axis=1)       # (females, minutes)\n",
    "smarr_median_4day = np.median(median_per_female, axis=0)  # (minutes,)\n",
    "\n",
    "# ============================================================\n",
    "# MAXIMAL DEALIGNMENT (NEGATIVE CONTROL)\n",
    "# ============================================================\n",
    "misaligned = np.empty_like(female_data)\n",
    "for i in range(n_females):\n",
    "    shift = (i * MINUTES_PER_DAY) % female_data.shape[1]\n",
    "    misaligned[i] = np.roll(female_data[i], -shift)\n",
    "\n",
    "reshaped_mis = misaligned.reshape(\n",
    "    n_females, n_cycles, MINUTES_PER_CYCLE\n",
    ")\n",
    "median_per_female_mis = np.median(reshaped_mis, axis=1)\n",
    "smarr_misaligned_median_4day = np.median(median_per_female_mis, axis=0)\n",
    "\n",
    "# ============================================================\n",
    "# PLATEAU STATISTICS ON MEDIAN 4-DAY PROFILE\n",
    "# ============================================================\n",
    "def plateau_stats_on_median(profile, label):\n",
    "    \"\"\"\n",
    "    profile: 1D array, length = 4 * 1440\n",
    "    Computes plateau duration (minutes) per cycle day in dark phase\n",
    "    using a fixed threshold = PLATEAU_FRAC * global max\n",
    "    \"\"\"\n",
    "    global_max = np.max(profile)\n",
    "    thresh = PLATEAU_FRAC * global_max\n",
    "\n",
    "    results = []\n",
    "    for day in range(DAYS_PER_CYCLE):\n",
    "        start = day * MINUTES_PER_DAY + DARK_START\n",
    "        end = day * MINUTES_PER_DAY + DARK_END\n",
    "\n",
    "        dark = profile[start:end]\n",
    "        above = dark >= thresh\n",
    "\n",
    "        plateau_duration = above.sum()  # minutes\n",
    "        results.append({\n",
    "            \"cycle_day\": day + 1,\n",
    "            \"plateau_duration_min\": plateau_duration\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(\"plateau_duration_min\", ascending=False)\n",
    "    df[\"rank\"] = np.arange(1, len(df) + 1)\n",
    "\n",
    "    print(f\"\\n=== Plateau ranking for {label} ===\")\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# RUN POSITIVE + NEGATIVE CONTROLS (SMARR)\n",
    "# ============================================================\n",
    "rank_smarr_aligned = plateau_stats_on_median(\n",
    "    smarr_median_4day, \"Smarr ALIGNED (positive control)\"\n",
    ")\n",
    "\n",
    "rank_smarr_misaligned = plateau_stats_on_median(\n",
    "    smarr_misaligned_median_4day, \"Smarr MISALIGNED (negative control)\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# OPTIONAL: RUN ON JAX REPLICATES IF MEDIANS ARE PROVIDED\n",
    "# ============================================================\n",
    "# If you already computed these elsewhere, just define:\n",
    "#   rep1_median_4day\n",
    "#   rep2_median_4day\n",
    "#\n",
    "# Each should be a 1D array of length 5760 (4 * 1440)\n",
    "\n",
    "if \"rep1_median_4day\" in globals():\n",
    "    plateau_stats_on_median(rep1_median_4day, \"JAX Rep1 median 4-day profile\")\n",
    "else:\n",
    "    print(\"\\n[INFO] rep1_median_4day not found — skipping Rep1.\")\n",
    "\n",
    "if \"rep2_median_4day\" in globals():\n",
    "    plateau_stats_on_median(rep2_median_4day, \"JAX Rep2 median 4-day profile\")\n",
    "else:\n",
    "    print(\"[INFO] rep2_median_4day not found — skipping Rep2.\")\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZATION: MEDIAN PROFILES WITH PLATEAU THRESHOLD\n",
    "# ============================================================\n",
    "def plot_median_profile(profile, title):\n",
    "    t_hours = np.arange(len(profile)) / 60.0\n",
    "    thresh = PLATEAU_FRAC * np.max(profile)\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.plot(t_hours, profile, linewidth=2)\n",
    "    plt.axhline(thresh, color=\"red\", linestyle=\"--\", label=f\"{int(PLATEAU_FRAC*100)}% of max\")\n",
    "\n",
    "    # Dark phase bars\n",
    "    for d in range(DAYS_PER_CYCLE):\n",
    "        plt.axvspan(d*24, d*24+12, color=\"black\", alpha=0.1)\n",
    "\n",
    "    plt.xlabel(\"Time (hours across 4-day cycle)\")\n",
    "    plt.ylabel(\"Activity\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_median_profile(smarr_median_4day, \"Smarr ALIGNED — Median 4-Day Profile\")\n",
    "plot_median_profile(smarr_misaligned_median_4day, \"Smarr MISALIGNED — Median 4-Day Profile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f79194-2c4e-4da5-97d7-37ed7ea748c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BUILD MEDIAN 4-DAY PROFILE (PER REPLICATE)\n",
    "#   - For each cage: mean across animals per timestamp\n",
    "#   - Fold into 4-day cycle: minute_in_cycle\n",
    "#   - Mean per minute_in_cycle across all included cycles\n",
    "#   - Median across cages\n",
    "# ============================================================\n",
    "def build_median_4day_profile(cfg):\n",
    "    baseline = pd.to_datetime(cfg[\"start\"])\n",
    "    cage_profiles = []\n",
    "\n",
    "    for cage_id in cfg[\"cages\"]:\n",
    "        df = load_activity(cage_id, cfg[\"start\"], cfg[\"end\"])\n",
    "\n",
    "        g = (\n",
    "            df.groupby(\"time\")[\"value\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        minutes = ((g[\"time\"] - baseline).dt.total_seconds() / 60).astype(int)\n",
    "        g[\"minute\"] = minutes\n",
    "\n",
    "        # keep complete 4-day cycles only\n",
    "        g = g[g[\"minute\"] >= 0]\n",
    "        max_full_cycles = (g[\"minute\"].max() + 1) // MINUTES_PER_CYCLE\n",
    "        g = g[g[\"minute\"] < max_full_cycles * MINUTES_PER_CYCLE]\n",
    "\n",
    "        g[\"minute_in_cycle\"] = g[\"minute\"] % MINUTES_PER_CYCLE\n",
    "\n",
    "        cage_profiles.append(\n",
    "            g.groupby(\"minute_in_cycle\")[\"value\"].mean()\n",
    "        )\n",
    "\n",
    "    median_profile = pd.concat(cage_profiles, axis=1).median(axis=1).values\n",
    "    return median_profile\n",
    "\n",
    "# ============================================================\n",
    "# PLATEAU DURATION STATS ON MEDIAN PROFILE (ROBUST THRESHOLD)\n",
    "#   - Threshold = PLATEAU_Q percentile of the 4-day median profile\n",
    "#   - For each cycle day, compute minutes in dark phase above threshold\n",
    "# ============================================================\n",
    "def plateau_duration_stats_on_median(profile, label, plateau_q=PLATEAU_Q):\n",
    "    thresh = float(np.nanpercentile(profile, plateau_q))\n",
    "\n",
    "    results = []\n",
    "    for day in range(DAYS_PER_CYCLE):\n",
    "        start = day * MINUTES_PER_DAY + DARK_START\n",
    "        end = day * MINUTES_PER_DAY + DARK_END\n",
    "\n",
    "        dark = profile[start:end]\n",
    "        plateau_duration = int(np.sum(dark >= thresh))\n",
    "\n",
    "        results.append({\n",
    "            \"cycle_day\": day + 1,\n",
    "            \"plateau_duration_min\": plateau_duration\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(results).sort_values(\"plateau_duration_min\", ascending=False).reset_index(drop=True)\n",
    "    out[\"rank\"] = np.arange(1, len(out) + 1)\n",
    "\n",
    "    print(f\"\\n=== Plateau duration ranking for {label} ===\")\n",
    "    print(f\"Threshold = {plateau_q}th percentile of 4-day median profile = {thresh:.4f}\")\n",
    "    print(out.to_string(index=False))\n",
    "\n",
    "    return out, thresh\n",
    "\n",
    "# ============================================================\n",
    "# PLOTTING\n",
    "# ============================================================\n",
    "def plot_median_profile(profile, title, thresh, plateau_q=PLATEAU_Q):\n",
    "    t_hours = np.arange(len(profile)) / 60.0\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.plot(t_hours, profile, linewidth=0.5)\n",
    "    plt.axhline(thresh, color=\"red\", linestyle=\"--\", label=f\"{plateau_q}th percentile threshold\")\n",
    "\n",
    "    # Dark phase shading (CT12–24 each day)\n",
    "    for d in range(DAYS_PER_CYCLE):\n",
    "        plt.axvspan(d * 24 + 12, d * 24 + 24, color=\"black\", alpha=0.10)\n",
    "\n",
    "    plt.xlabel(\"Time (hours across 4-day cycle)\")\n",
    "    plt.ylabel(\"Locomotion (fraction of time)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# RUN FOR REP1 + REP2\n",
    "# ============================================================\n",
    "rep1_median_4day = build_median_4day_profile(VEHICLE_CAGES[\"Rep1\"])\n",
    "rep2_median_4day = build_median_4day_profile(VEHICLE_CAGES[\"Rep2\"])\n",
    "\n",
    "rank_rep1, thresh_rep1 = plateau_duration_stats_on_median(rep1_median_4day, \"JAX Rep1 median 4-day profile\", plateau_q=PLATEAU_Q)\n",
    "rank_rep2, thresh_rep2 = plateau_duration_stats_on_median(rep2_median_4day, \"JAX Rep2 median 4-day profile\", plateau_q=PLATEAU_Q)\n",
    "\n",
    "plot_median_profile(rep1_median_4day, \"JAX Rep1 – Median 4-Day Profile (Vehicle)\", thresh_rep1, plateau_q=PLATEAU_Q)\n",
    "plot_median_profile(rep2_median_4day, \"JAX Rep2 – Median 4-Day Profile (Vehicle)\", thresh_rep2, plateau_q=PLATEAU_Q)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ca16e-376f-417a-adb7-ca03198768f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# SMARR: ALIGNED vs MAXIMALLY DEALIGNED\n",
    "# Plateau duration on MEDIAN 4-day profile using PERCENTILE threshold\n",
    "# ============================================================\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "MINUTES_PER_DAY = 1440\n",
    "DAYS_PER_CYCLE = 4\n",
    "MINUTES_PER_CYCLE = DAYS_PER_CYCLE * MINUTES_PER_DAY\n",
    "\n",
    "# Smarr convention in your scripts: t=0 is lights OFF, so dark is first 12h\n",
    "DARK_START = 0\n",
    "DARK_END = 720\n",
    "\n",
    "# Robust threshold: percentile of the full 4-day median profile\n",
    "PLATEAU_Q = 85  # try 80–90; 85 is a good default\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD SMARR FEMALE DATA\n",
    "# ----------------------------\n",
    "df_smarr = pd.read_csv(\"mice data.xlsx - FemAct (1).csv\")\n",
    "\n",
    "female_cols = [c for c in df_smarr.columns if str(c).lower().startswith(\"fem\")]\n",
    "if len(female_cols) == 0:\n",
    "    raise ValueError(\"No female columns found (expected columns starting with 'fem').\")\n",
    "\n",
    "female_data = df_smarr[female_cols].to_numpy().T  # (n_females, n_timepoints)\n",
    "n_females, n_timepoints = female_data.shape\n",
    "print(f\"Loaded Smarr: n_females={n_females}, n_timepoints={n_timepoints} minutes\")\n",
    "\n",
    "# keep complete 4-day cycles only\n",
    "n_cycles = n_timepoints // MINUTES_PER_CYCLE\n",
    "if n_cycles < 1:\n",
    "    raise ValueError(\"Not enough data for a complete 4-day cycle.\")\n",
    "\n",
    "female_data = female_data[:, :n_cycles * MINUTES_PER_CYCLE]\n",
    "print(f\"Using complete cycles: n_cycles={n_cycles} (total minutes={female_data.shape[1]})\")\n",
    "\n",
    "# ----------------------------\n",
    "# BUILD MEDIAN 4-DAY PROFILE (ALIGNED)\n",
    "# ----------------------------\n",
    "reshaped = female_data.reshape(n_females, n_cycles, MINUTES_PER_CYCLE)\n",
    "median_per_female = np.median(reshaped, axis=1)          # (n_females, 5760)\n",
    "smarr_median_4day = np.median(median_per_female, axis=0) # (5760,)\n",
    "\n",
    "# ----------------------------\n",
    "# MAXIMAL DEALIGNMENT (Smarr-style)\n",
    "# advance each subsequent female by +1 day (circular)\n",
    "# ----------------------------\n",
    "misaligned = np.empty_like(female_data)\n",
    "for i in range(n_females):\n",
    "    shift = (i * MINUTES_PER_DAY) % female_data.shape[1]\n",
    "    misaligned[i] = np.roll(female_data[i], -shift)\n",
    "\n",
    "reshaped_mis = misaligned.reshape(n_females, n_cycles, MINUTES_PER_CYCLE)\n",
    "median_per_female_mis = np.median(reshaped_mis, axis=1)\n",
    "smarr_misaligned_median_4day = np.median(median_per_female_mis, axis=0)\n",
    "\n",
    "# ----------------------------\n",
    "# PLATEAU DURATION ON MEDIAN PROFILE (percentile threshold)\n",
    "# ----------------------------\n",
    "def plateau_duration_rank_on_median(profile, label, q=PLATEAU_Q):\n",
    "    thresh = float(np.nanpercentile(profile, q))\n",
    "    rows = []\n",
    "    for day in range(DAYS_PER_CYCLE):\n",
    "        s = day * MINUTES_PER_DAY + DARK_START\n",
    "        e = day * MINUTES_PER_DAY + DARK_END\n",
    "        dark = profile[s:e]\n",
    "        plateau_duration = int(np.sum(dark >= thresh))\n",
    "        rows.append({\"cycle_day\": day + 1, \"plateau_duration_min\": plateau_duration})\n",
    "    out = pd.DataFrame(rows).sort_values(\"plateau_duration_min\", ascending=False).reset_index(drop=True)\n",
    "    out[\"rank\"] = np.arange(1, len(out) + 1)\n",
    "\n",
    "    print(f\"\\n=== {label} ===\")\n",
    "    print(f\"Threshold = {q}th percentile of 4-day median profile = {thresh:.4f}\")\n",
    "    print(out.to_string(index=False))\n",
    "    return out, thresh\n",
    "\n",
    "rank_aligned, thr_aligned = plateau_duration_rank_on_median(\n",
    "    smarr_median_4day, f\"Smarr ALIGNED (positive control) – plateau duration\", q=PLATEAU_Q\n",
    ")\n",
    "rank_mis, thr_mis = plateau_duration_rank_on_median(\n",
    "    smarr_misaligned_median_4day, f\"Smarr MISALIGNED (negative control) – plateau duration\", q=PLATEAU_Q\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# PLOTS: median profiles + thresholds\n",
    "# ----------------------------\n",
    "def plot_profile(profile, title, thresh, q=PLATEAU_Q):\n",
    "    t_hours = np.arange(len(profile)) / 60.0\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.plot(t_hours, profile, linewidth=0.5)\n",
    "    plt.axhline(thresh, color=\"red\", linestyle=\"--\", label=f\"{q}th percentile threshold\")\n",
    "    # dark shading: first 12h each day in this convention\n",
    "    for d in range(DAYS_PER_CYCLE):\n",
    "        plt.axvspan(d * 24, d * 24 + 12, color=\"black\", alpha=0.10)\n",
    "    plt.xlabel(\"Time (hours across 4-day cycle)\")\n",
    "    plt.ylabel(\"LA (counts)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_profile(smarr_median_4day, \"Smarr ALIGNED — Median 4-Day Profile\", thr_aligned, q=PLATEAU_Q)\n",
    "plot_profile(smarr_misaligned_median_4day, \"Smarr MISALIGNED — Median 4-Day Profile\", thr_mis, q=PLATEAU_Q)\n",
    "\n",
    "# ----------------------------\n",
    "# OPTIONAL: quick robustness sweep over percentiles\n",
    "# ----------------------------\n",
    "def robustness_sweep(profile_aligned, profile_mis, qs=(75, 80, 85, 90, 95)):\n",
    "    rows = []\n",
    "    for q in qs:\n",
    "        ra, _ = plateau_duration_rank_on_median(profile_aligned, f\"[Sweep] ALIGNED q={q}\", q=q)\n",
    "        rm, _ = plateau_duration_rank_on_median(profile_mis, f\"[Sweep] MISALIGNED q={q}\", q=q)\n",
    "        rows.append({\n",
    "            \"q\": q,\n",
    "            \"aligned_top_day\": int(ra.iloc[0][\"cycle_day\"]),\n",
    "            \"aligned_top_duration\": int(ra.iloc[0][\"plateau_duration_min\"]),\n",
    "            \"mis_top_day\": int(rm.iloc[0][\"cycle_day\"]),\n",
    "            \"mis_top_duration\": int(rm.iloc[0][\"plateau_duration_min\"]),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Uncomment if you want the sweep table:\n",
    "# sweep_df = robustness_sweep(smarr_median_4day, smarr_misaligned_median_4day, qs=(75,80,85,90,95))\n",
    "# print(\"\\nRobustness sweep summary:\")\n",
    "# print(sweep_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f744ba-91ac-4d2a-965c-2e9d6cd1b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# PLATEAU DURATION ON ALL DAYS\n",
    "#   - Smarr aligned (all days)\n",
    "#   - Smarr maximally dealigned (all days)\n",
    "#   - JAX Rep1 vehicle (all days)  [ASSUMES already loaded in ACTIVITY_CACHE]\n",
    "#   - JAX Rep2 vehicle (all days)  [ASSUMES already loaded in ACTIVITY_CACHE]\n",
    "#\n",
    "# Plateau duration definition (consistent everywhere):\n",
    "#   For each animal and day:\n",
    "#     plateau_duration = # of dark-phase minutes with activity >= animal-specific threshold\n",
    "#   Threshold per animal:\n",
    "#     threshold = qth percentile of THAT ANIMAL'S dark-phase values across the whole window\n",
    "#\n",
    "# Rankings:\n",
    "#   For each dataset:\n",
    "#     rank days by mean plateau_duration across animals (descending)\n",
    "# ============================================================\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "Q_THRESH = 85  # percentile for per-animal threshold (robust; try 80–90)\n",
    "\n",
    "# Smarr convention in your earlier scripts: dark is first 12h of each day (minutes 0–720)\n",
    "SMARR_MIN_PER_DAY = 1440\n",
    "SMARR_DARK_START = 0\n",
    "SMARR_DARK_END = 720\n",
    "\n",
    "# JAX convention in your earlier vehicle plots: baseline start = lights-on (6am),\n",
    "# so dark is 12–24h after baseline each day (minutes 720–1440)\n",
    "JAX_MIN_PER_DAY = 1440\n",
    "JAX_DARK_START = 720\n",
    "JAX_DARK_END = 1440\n",
    "\n",
    "# For JAX, we will ONLY use these cages (vehicle) and baseline windows.\n",
    "# (Data should already be loaded in ACTIVITY_CACHE by your earlier loader.)\n",
    "VEHICLE_CAGES = {\n",
    "    \"Rep1\": {\n",
    "        \"cages\": [4918, 4922, 4923],\n",
    "        \"start\": \"2025-01-10 06:00:00\",\n",
    "        \"end\":   \"2025-01-22 06:00:00\",\n",
    "    },\n",
    "    \"Rep2\": {\n",
    "        \"cages\": [4928, 4929, 4934],\n",
    "        \"start\": \"2025-01-25 06:00:00\",\n",
    "        \"end\":   \"2025-02-04 06:00:00\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# HELPERS\n",
    "# ----------------------------\n",
    "def _rank_days(df_daily: pd.DataFrame, metric: str = \"plateau_duration_min\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    df_daily columns expected: animal_id, day, plateau_duration_min (and optionally cage_id/rep)\n",
    "    Returns day-level ranking by mean plateau_duration across animals.\n",
    "    \"\"\"\n",
    "    out = (\n",
    "        df_daily.groupby(\"day\")[metric]\n",
    "        .agg(mean=\"mean\", median=\"median\", sd=\"std\", n=\"count\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"mean\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    out[\"rank\"] = np.arange(1, len(out) + 1)\n",
    "    return out\n",
    "\n",
    "def _plot_day_ranking(rank_df: pd.DataFrame, title: str):\n",
    "    x = rank_df[\"day\"].to_numpy()\n",
    "    y = rank_df[\"mean\"].to_numpy()\n",
    "    s = rank_df[\"sd\"].fillna(0.0).to_numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 3.5))\n",
    "    plt.plot(x, y, linewidth=2, label=\"Mean across animals\")\n",
    "    plt.fill_between(x, y - s, y + s, alpha=0.2, label=\"±1 SD\")\n",
    "    plt.xticks(x.astype(int))\n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.ylabel(\"Plateau duration (min)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _heatmap_plateau(df_daily: pd.DataFrame, title: str, zscore_within_animal: bool = True):\n",
    "    \"\"\"\n",
    "    Heatmap: rows animals, cols days, values plateau_duration_min\n",
    "    \"\"\"\n",
    "    mat = df_daily.pivot_table(index=\"animal_id\", columns=\"day\", values=\"plateau_duration_min\", aggfunc=\"mean\")\n",
    "    if zscore_within_animal:\n",
    "        mat = mat.sub(mat.mean(axis=1), axis=0)\n",
    "        mat = mat.div(mat.std(axis=1).replace(0, np.nan), axis=0)\n",
    "\n",
    "    # sort animals by peak day for readability\n",
    "    peak_day = mat.idxmax(axis=1)\n",
    "    mat = mat.loc[peak_day.sort_values().index]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    im = plt.imshow(mat.values, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.ylabel(\"Animal (sorted by peak day)\")\n",
    "    plt.title(title + (\" (z-score within animal)\" if zscore_within_animal else \"\"))\n",
    "    plt.xticks(np.arange(mat.shape[1]), mat.columns.astype(int))\n",
    "    plt.yticks([])\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\"Plateau duration (z)\" if zscore_within_animal else \"Plateau duration (min)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# SMARR: compute per-female per-day plateau_duration (aligned or misaligned)\n",
    "# ----------------------------\n",
    "def smarr_daily_plateau(df_smarr: pd.DataFrame, dealign: bool = False, q: int = Q_THRESH) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    df_smarr must contain fem* columns (minute-resolution LA counts).\n",
    "    Returns df_daily with columns: animal_id, day, plateau_duration_min\n",
    "    \"\"\"\n",
    "    female_cols = [c for c in df_smarr.columns if str(c).lower().startswith(\"fem\")]\n",
    "    if len(female_cols) == 0:\n",
    "        raise ValueError(\"Smarr: No female columns found (expected columns starting with 'fem').\")\n",
    "\n",
    "    X = df_smarr[female_cols].to_numpy().T  # (n_females, n_timepoints)\n",
    "    n_fem, n_tp = X.shape\n",
    "    n_days = n_tp // SMARR_MIN_PER_DAY\n",
    "    if n_days < 1:\n",
    "        raise ValueError(\"Smarr: Not enough data for at least 1 full day.\")\n",
    "\n",
    "    X = X[:, :n_days * SMARR_MIN_PER_DAY]\n",
    "    n_tp = X.shape[1]\n",
    "\n",
    "    if dealign:\n",
    "        Xm = np.empty_like(X)\n",
    "        for i in range(n_fem):\n",
    "            shift = (i * SMARR_MIN_PER_DAY) % n_tp\n",
    "            Xm[i] = np.roll(X[i], -shift)\n",
    "        X = Xm\n",
    "\n",
    "    # Precompute per-female threshold from all dark-phase values across ALL days\n",
    "    thresholds = np.zeros(n_fem, dtype=float)\n",
    "    for i in range(n_fem):\n",
    "        # dark-phase minutes across all days: take first 12h of each day\n",
    "        dark_vals = []\n",
    "        for d in range(n_days):\n",
    "            day_slice = X[i, d*SMARR_MIN_PER_DAY:(d+1)*SMARR_MIN_PER_DAY]\n",
    "            dark = day_slice[SMARR_DARK_START:SMARR_DARK_END]\n",
    "            dark_vals.append(dark)\n",
    "        dark_vals = np.concatenate(dark_vals)\n",
    "        thresholds[i] = float(np.nanpercentile(dark_vals, q))\n",
    "\n",
    "    rows = []\n",
    "    for i in range(n_fem):\n",
    "        thr = thresholds[i]\n",
    "        for d in range(n_days):\n",
    "            day_slice = X[i, d*SMARR_MIN_PER_DAY:(d+1)*SMARR_MIN_PER_DAY]\n",
    "            dark = day_slice[SMARR_DARK_START:SMARR_DARK_END]\n",
    "            plateau_duration = int(np.sum(dark >= thr))  # minutes\n",
    "            rows.append({\"animal_id\": i, \"day\": d + 1, \"plateau_duration_min\": plateau_duration})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ----------------------------\n",
    "# JAX: build per-animal per-day plateau_duration from already-loaded ACTIVITY_CACHE\n",
    "# ----------------------------\n",
    "def _get_jax_loaded_df_for_rep(rep_label: str, cfg: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pulls already-loaded cage windows from global ACTIVITY_CACHE without re-querying S3.\n",
    "    Expects ACTIVITY_CACHE keys like (cage_id, start, end) -> df(time, animal_id, value)\n",
    "    \"\"\"\n",
    "    if \"ACTIVITY_CACHE\" not in globals():\n",
    "        raise ValueError(\"JAX: ACTIVITY_CACHE not found. Run your JAX loading cell first so data are cached.\")\n",
    "\n",
    "    parts = []\n",
    "    for cage_id in cfg[\"cages\"]:\n",
    "        key = (cage_id, cfg[\"start\"], cfg[\"end\"])\n",
    "        if key not in ACTIVITY_CACHE:\n",
    "            raise ValueError(\n",
    "                f\"JAX: Missing cached data for key={key}. \"\n",
    "                \"Load it first with your load_activity(...) caching code.\"\n",
    "            )\n",
    "        df = ACTIVITY_CACHE[key].copy()\n",
    "        df[\"cage_id\"] = cage_id\n",
    "        df[\"rep\"] = rep_label\n",
    "        parts.append(df)\n",
    "\n",
    "    if len(parts) == 0:\n",
    "        return pd.DataFrame(columns=[\"time\", \"animal_id\", \"value\", \"cage_id\", \"rep\"])\n",
    "\n",
    "    out = pd.concat(parts, ignore_index=True)\n",
    "    out[\"time\"] = pd.to_datetime(out[\"time\"])\n",
    "    return out\n",
    "\n",
    "def jax_daily_plateau(rep_label: str, cfg: dict, q: int = Q_THRESH) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses cached JAX dataframes (already loaded) to compute per-animal per-day plateau_duration in dark phase.\n",
    "    \"\"\"\n",
    "    df = _get_jax_loaded_df_for_rep(rep_label, cfg)\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"JAX: No cached data found for {rep_label}.\")\n",
    "\n",
    "    baseline = pd.to_datetime(cfg[\"start\"])\n",
    "    # day index (1-based) from baseline\n",
    "    dt_minutes = ((df[\"time\"] - baseline).dt.total_seconds() / 60.0).astype(int)\n",
    "    df = df.assign(\n",
    "        minute_from_start=dt_minutes,\n",
    "        day=(dt_minutes // JAX_MIN_PER_DAY) + 1,\n",
    "        minute_in_day=dt_minutes % JAX_MIN_PER_DAY\n",
    "    )\n",
    "\n",
    "    # restrict to dark phase minutes within each day\n",
    "    df_dark = df[(df[\"minute_in_day\"] >= JAX_DARK_START) & (df[\"minute_in_day\"] < JAX_DARK_END)].copy()\n",
    "\n",
    "    # per-animal threshold from all dark-phase values across entire window\n",
    "    thr = df_dark.groupby(\"animal_id\")[\"value\"].apply(lambda s: float(np.nanpercentile(s.to_numpy(), q)))\n",
    "    df_dark = df_dark.join(thr.rename(\"thr\"), on=\"animal_id\")\n",
    "\n",
    "    # plateau duration per animal-day = count of minutes where value >= thr\n",
    "    df_daily = (\n",
    "        df_dark.assign(above=lambda d: d[\"value\"] >= d[\"thr\"])\n",
    "        .groupby([\"animal_id\", \"day\"], as_index=False)[\"above\"]\n",
    "        .sum()\n",
    "        .rename(columns={\"above\": \"plateau_duration_min\"})  # 60s resolution => 1 row per minute window\n",
    "    )\n",
    "\n",
    "    df_daily[\"rep\"] = rep_label\n",
    "    return df_daily\n",
    "\n",
    "# ============================================================\n",
    "# RUN: SMARR (aligned + misaligned)\n",
    "# ============================================================\n",
    "df_smarr = pd.read_csv(\"mice data.xlsx - FemAct (1).csv\")\n",
    "\n",
    "smarr_aligned_daily = smarr_daily_plateau(df_smarr, dealign=False, q=Q_THRESH)\n",
    "smarr_misaligned_daily = smarr_daily_plateau(df_smarr, dealign=True, q=Q_THRESH)\n",
    "\n",
    "smarr_aligned_rank = _rank_days(smarr_aligned_daily)\n",
    "smarr_misaligned_rank = _rank_days(smarr_misaligned_daily)\n",
    "\n",
    "print(\"\\n=== Smarr ALIGNED (all days) — day rankings ===\")\n",
    "print(smarr_aligned_rank.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Smarr MISALIGNED (all days) — day rankings ===\")\n",
    "print(smarr_misaligned_rank.to_string(index=False))\n",
    "\n",
    "\n",
    "_heatmap_plateau(smarr_aligned_daily, f\"Smarr ALIGNED — Per-female plateau duration (q={Q_THRESH})\", zscore_within_animal=True)\n",
    "_heatmap_plateau(smarr_misaligned_daily, f\"Smarr MISALIGNED — Per-female plateau duration (q={Q_THRESH})\", zscore_within_animal=True)\n",
    "\n",
    "# ============================================================\n",
    "# RUN: JAX Rep1 + Rep2 (ASSUMES already loaded/cached)\n",
    "# ============================================================\n",
    "rep1_daily = jax_daily_plateau(\"Rep1\", VEHICLE_CAGES[\"Rep1\"], q=Q_THRESH)\n",
    "rep2_daily = jax_daily_plateau(\"Rep2\", VEHICLE_CAGES[\"Rep2\"], q=Q_THRESH)\n",
    "\n",
    "rep1_rank = _rank_days(rep1_daily)\n",
    "rep2_rank = _rank_days(rep2_daily)\n",
    "\n",
    "print(\"\\n=== JAX Rep1 (all days) — day rankings ===\")\n",
    "print(rep1_rank.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== JAX Rep2 (all days) — day rankings ===\")\n",
    "print(rep2_rank.to_string(index=False))\n",
    "\n",
    "\n",
    "_heatmap_plateau(rep1_daily, f\"JAX Rep1 (Vehicle) — Per-animal plateau duration (q={Q_THRESH})\", zscore_within_animal=True)\n",
    "_heatmap_plateau(rep2_daily, f\"JAX Rep2 (Vehicle) — Per-animal plateau duration (q={Q_THRESH})\", zscore_within_animal=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224d88f-b18b-458e-9ddd-19d87c246427",
   "metadata": {},
   "source": [
    "## 4. Population-Level Permutation Test\n",
    "\n",
    "### Objective\n",
    "\n",
    "Test whether the highest plateau days (top-k) show significantly\n",
    "greater locomotor plateau duration than the remaining days\n",
    "at the population level.\n",
    "\n",
    "This evaluates whether estrus-like structure is detectable\n",
    "across the entire replicate, not just within individual cages.\n",
    "\n",
    "---\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "1. For each day:\n",
    "   - Compute mean plateau duration across all animals\n",
    "     (within replicate)\n",
    "\n",
    "2. Rank days by mean plateau duration (descending)\n",
    "\n",
    "3. Define:\n",
    "   Top-k days = k highest-ranked days  \n",
    "   Rest days = remaining days  \n",
    "\n",
    "4. Compute observed statistic:\n",
    "\n",
    "T_obs = mean(top-k days) − mean(rest days)\n",
    "\n",
    "---\n",
    "\n",
    "### Permutation Procedure\n",
    "\n",
    "To generate the null distribution:\n",
    "\n",
    "For each permutation:\n",
    "\n",
    "1. Shuffle day labels within each animal\n",
    "   (preserves animal-level structure and variance)\n",
    "\n",
    "2. Recompute:\n",
    "   - Daily mean plateau duration\n",
    "   - Day rankings\n",
    "   - T_perm\n",
    "\n",
    "3. Repeat N times (e.g., 10,000)\n",
    "\n",
    "---\n",
    "\n",
    "### Empirical p-value\n",
    "\n",
    "p = proportion of permutations where  \n",
    "T_perm ≥ T_obs\n",
    "\n",
    "Small p-value → Evidence that top-k days are not random  \n",
    "Large p-value → No detectable population-level structure\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Significant result:\n",
    "→ Structured estrus-linked plateau pattern detectable at population scale\n",
    "\n",
    "Non-significant result:\n",
    "→ Plateau structure may be:\n",
    "   - Distributed across multiple days\n",
    "   - Cage-specific\n",
    "   - Weak relative to baseline variability\n",
    "   - Masked by replicate timing differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955da6c-ea39-46fa-9d0f-f4a439279598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_smarr = pd.read_csv(\"mice data.xlsx - FemAct (1).csv\")\n",
    "\n",
    "female_cols = [c for c in df_smarr.columns if str(c).lower().startswith(\"fem\")]\n",
    "female_data = df_smarr[female_cols].to_numpy().T\n",
    "\n",
    "n_females, n_timepoints = female_data.shape\n",
    "n_days = n_timepoints / 1440\n",
    "\n",
    "print(f\"Females: {n_females}\")\n",
    "print(f\"Timepoints (minutes): {n_timepoints}\")\n",
    "print(f\"Days: {n_days}\")\n",
    "print(f\"Complete days: {n_timepoints // 1440}\")\n",
    "print(f\"Remainder minutes: {n_timepoints % 1440}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2db83-74e7-40cb-909a-d1d565d6ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estrus_days = {1, 5}\n",
    "\n",
    "obs = (\n",
    "    smarr_aligned_daily\n",
    "    .assign(is_estrus=lambda d: d[\"day\"].isin(estrus_days))\n",
    "    .groupby([\"animal_id\", \"is_estrus\"])[\"plateau_duration_min\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "T_obs = (obs[True] - obs[False]).mean()\n",
    "rng = np.random.default_rng(0)\n",
    "n_perm = 10000\n",
    "T_perm = np.zeros(n_perm)\n",
    "\n",
    "for i in range(n_perm):\n",
    "    perm = smarr_aligned_daily.copy()\n",
    "    perm[\"day\"] = (\n",
    "        perm.groupby(\"animal_id\")[\"day\"]\n",
    "        .transform(lambda x: rng.permutation(x.values))\n",
    "    )\n",
    "\n",
    "    tmp = (\n",
    "        perm.assign(is_estrus=lambda d: d[\"day\"].isin(estrus_days))\n",
    "        .groupby([\"animal_id\", \"is_estrus\"])[\"plateau_duration_min\"]\n",
    "        .mean()\n",
    "        .unstack()\n",
    "    )\n",
    "\n",
    "    T_perm[i] = (tmp[True] - tmp[False]).mean()\n",
    "p_value = (np.sum(T_perm >= T_obs) + 1) / (n_perm + 1)\n",
    "print(\"Observed T:\", T_obs)\n",
    "print(\"Permutation p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f958ed-9249-41fc-9c77-771e6ff38902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PERMUTATION TEST: Smarr MISALIGNED\n",
    "# ------------------------------------------------------------\n",
    "# Assumes you already have:\n",
    "#   smarr_misaligned_daily\n",
    "# with columns: animal_id, day, plateau_duration_min\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "estrus_days = {1, 5}\n",
    "rng = np.random.default_rng(0)\n",
    "n_perm = 10000\n",
    "\n",
    "# ----- observed statistic -----\n",
    "obs = (\n",
    "    smarr_misaligned_daily\n",
    "    .assign(is_estrus=lambda d: d[\"day\"].isin(estrus_days))\n",
    "    .groupby([\"animal_id\", \"is_estrus\"])[\"plateau_duration_min\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "T_obs_mis = (obs[True] - obs[False]).mean()\n",
    "\n",
    "# ----- permutation distribution -----\n",
    "T_perm_mis = np.zeros(n_perm)\n",
    "\n",
    "for i in range(n_perm):\n",
    "    perm = smarr_misaligned_daily.copy()\n",
    "    perm[\"day\"] = (\n",
    "        perm.groupby(\"animal_id\")[\"day\"]\n",
    "        .transform(lambda x: rng.permutation(x.values))\n",
    "    )\n",
    "\n",
    "    tmp = (\n",
    "        perm.assign(is_estrus=lambda d: d[\"day\"].isin(estrus_days))\n",
    "        .groupby([\"animal_id\", \"is_estrus\"])[\"plateau_duration_min\"]\n",
    "        .mean()\n",
    "        .unstack()\n",
    "    )\n",
    "\n",
    "    T_perm_mis[i] = (tmp[True] - tmp[False]).mean()\n",
    "\n",
    "# ----- p-value -----\n",
    "p_value_mis = (np.sum(T_perm_mis >= T_obs_mis) + 1) / (n_perm + 1)\n",
    "\n",
    "print(\"Smarr MISALIGNED:\")\n",
    "print(\"Observed T:\", T_obs_mis)\n",
    "print(\"Permutation p-value:\", p_value_mis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b46ff1-665c-4fe3-b254-734c6e19c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# PERMUTATION TESTS FOR JAX REP1 + REP2 (NO GROUND-TRUTH ESTRUS)\n",
    "#\n",
    "# Assumes you already computed:\n",
    "#   rep1_daily, rep2_daily\n",
    "# each with columns: animal_id, day, plateau_duration_min\n",
    "#\n",
    "# Null: day labels are exchangeable WITHIN each animal.\n",
    "# Permutation: shuffle day labels within each animal.\n",
    "#\n",
    "# Test statistic options:\n",
    "#   1) \"max_mean_day\" (recommended): max over days of (mean plateau_duration across animals)\n",
    "#   2) \"topk_minus_rest\": mean(top-k day means) - mean(rest day means)\n",
    "# ============================================================\n",
    "\n",
    "RNG_SEED = 0\n",
    "N_PERM = 10000\n",
    "\n",
    "def _obs_day_means(df_daily: pd.DataFrame) -> pd.Series:\n",
    "    return df_daily.groupby(\"day\")[\"plateau_duration_min\"].mean().sort_index()\n",
    "\n",
    "def _stat_max_mean_day(day_means: pd.Series) -> float:\n",
    "    return float(day_means.max())\n",
    "\n",
    "def _stat_topk_minus_rest(day_means: pd.Series, k: int = 1) -> float:\n",
    "    vals = day_means.to_numpy()\n",
    "    if len(vals) <= k:\n",
    "        return float(\"nan\")\n",
    "    topk = np.sort(vals)[-k:]\n",
    "    rest = np.sort(vals)[:-k]\n",
    "    return float(topk.mean() - rest.mean())\n",
    "\n",
    "def permutation_test_jax(\n",
    "    df_daily: pd.DataFrame,\n",
    "    stat: str = \"max_mean_day\",\n",
    "    k: int = 1,\n",
    "    n_perm: int = N_PERM,\n",
    "    seed: int = RNG_SEED,\n",
    "    plot: bool = True,\n",
    "    title_prefix: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns dict with observed statistic, permutation p-value, perm distribution, and observed day means.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # observed\n",
    "    day_means_obs = _obs_day_means(df_daily)\n",
    "    if stat == \"max_mean_day\":\n",
    "        T_obs = _stat_max_mean_day(day_means_obs)\n",
    "    elif stat == \"topk_minus_rest\":\n",
    "        T_obs = _stat_topk_minus_rest(day_means_obs, k=k)\n",
    "    else:\n",
    "        raise ValueError(\"stat must be 'max_mean_day' or 'topk_minus_rest'\")\n",
    "\n",
    "    # permutation distribution\n",
    "    T_perm = np.empty(n_perm, dtype=float)\n",
    "\n",
    "    # pre-split by animal for speed\n",
    "    grouped = list(df_daily.groupby(\"animal_id\", sort=False))\n",
    "\n",
    "    for i in range(n_perm):\n",
    "        perm_parts = []\n",
    "        for _, g in grouped:\n",
    "            g2 = g.copy()\n",
    "            g2[\"day\"] = rng.permutation(g2[\"day\"].to_numpy())\n",
    "            perm_parts.append(g2)\n",
    "        perm_df = pd.concat(perm_parts, ignore_index=True)\n",
    "\n",
    "        dm = perm_df.groupby(\"day\")[\"plateau_duration_min\"].mean().sort_index()\n",
    "        if stat == \"max_mean_day\":\n",
    "            T_perm[i] = _stat_max_mean_day(dm)\n",
    "        else:\n",
    "            T_perm[i] = _stat_topk_minus_rest(dm, k=k)\n",
    "\n",
    "    # one-sided p-value (large = more \"estrus-like\" structure)\n",
    "    p_value = (np.sum(T_perm >= T_obs) + 1) / (n_perm + 1)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"{title_prefix} Permutation test\")\n",
    "    print(f\"Statistic: {stat}\" + (f\" (k={k})\" if stat == \"topk_minus_rest\" else \"\"))\n",
    "    print(f\"Observed T: {T_obs:.6f}\")\n",
    "    print(f\"Permutation p-value: {p_value:.6g}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # optional plots\n",
    "    if plot:\n",
    "        # Null distribution with observed marked\n",
    "        plt.figure(figsize=(8, 3.5))\n",
    "        plt.hist(T_perm, bins=40)\n",
    "        plt.axvline(T_obs, linestyle=\"--\", linewidth=2)\n",
    "        plt.title(f\"{title_prefix} null distribution ({stat})\")\n",
    "        plt.xlabel(\"Permutation statistic\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Observed day means bar/line\n",
    "        plt.figure(figsize=(10, 3.5))\n",
    "        plt.plot(day_means_obs.index.to_numpy(), day_means_obs.to_numpy(), linewidth=2)\n",
    "        top_day = int(day_means_obs.idxmax())\n",
    "        plt.axvline(top_day, linestyle=\"--\", linewidth=1.5, alpha=0.8, label=f\"Top day = {top_day}\")\n",
    "        plt.title(f\"{title_prefix} observed day means (plateau duration)\")\n",
    "        plt.xlabel(\"Day\")\n",
    "        plt.ylabel(\"Mean plateau duration (min)\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"T_obs\": T_obs,\n",
    "        \"p_value\": p_value,\n",
    "        \"T_perm\": T_perm,\n",
    "        \"day_means_obs\": day_means_obs,\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# RUN: REP1 + REP2\n",
    "# ============================================================\n",
    "# Recommended primary test: max_mean_day (controls \"cherry-picking\" top day via permutation max)\n",
    "res_rep1 = permutation_test_jax(\n",
    "    rep1_daily,\n",
    "    stat=\"max_mean_day\",\n",
    "    n_perm=N_PERM,\n",
    "    seed=RNG_SEED,\n",
    "    plot=True,\n",
    "    title_prefix=\"JAX Rep1\",\n",
    ")\n",
    "\n",
    "res_rep2 = permutation_test_jax(\n",
    "    rep2_daily,\n",
    "    stat=\"max_mean_day\",\n",
    "    n_perm=N_PERM,\n",
    "    seed=RNG_SEED,\n",
    "    plot=True,\n",
    "    title_prefix=\"JAX Rep2\",\n",
    ")\n",
    "\n",
    "# Optional: also test \"top-2 days vs rest\" (often matches biology: two estrus-like peaks in long windows)\n",
    "# res_rep1_k2 = permutation_test_jax(rep1_daily, stat=\"topk_minus_rest\", k=2, n_perm=N_PERM, seed=RNG_SEED, plot=True, title_prefix=\"JAX Rep1\")\n",
    "# res_rep2_k2 = permutation_test_jax(rep2_daily, stat=\"topk_minus_rest\", k=2, n_perm=N_PERM, seed=RNG_SEED, plot=True, title_prefix=\"JAX Rep2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec547062-394e-4797-8500-c2ef0beba792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# PLATEAU DURATION ON ALL DAYS (boxplots by day)\n",
    "# ============================================================\n",
    "\n",
    "Q_THRESH = 85\n",
    "\n",
    "SMARR_MIN_PER_DAY = 1440\n",
    "SMARR_DARK_START, SMARR_DARK_END = 0, 720          # Smarr: dark first 12h\n",
    "\n",
    "JAX_MIN_PER_DAY = 1440\n",
    "JAX_DARK_START, JAX_DARK_END = 720, 1440           # JAX: dark second 12h (baseline start = lights-on)\n",
    "\n",
    "VEHICLE_CAGES = {\n",
    "    \"Rep1\": {\"cages\": [4918, 4922, 4923], \"start\": \"2025-01-10 06:00:00\", \"end\": \"2025-01-22 06:00:00\"},\n",
    "    \"Rep2\": {\"cages\": [4928, 4929, 4934], \"start\": \"2025-01-25 06:00:00\", \"end\": \"2025-02-04 06:00:00\"},\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# HELPERS\n",
    "# ----------------------------\n",
    "def _rank_days(df_daily: pd.DataFrame, metric: str = \"plateau_duration_min\") -> pd.DataFrame:\n",
    "    out = (\n",
    "        df_daily.groupby(\"day\")[metric]\n",
    "        .agg(mean=\"mean\", median=\"median\", sd=\"std\", n=\"count\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"mean\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    out[\"rank\"] = np.arange(1, len(out) + 1)\n",
    "    return out\n",
    "\n",
    "def _boxplot_by_day(df_daily: pd.DataFrame, title: str, metric: str = \"plateau_duration_min\"):\n",
    "    \"\"\"\n",
    "    Boxplot per day: distribution across animals (one value per animal-day).\n",
    "    \"\"\"\n",
    "    d = df_daily.copy()\n",
    "    d[\"day\"] = d[\"day\"].astype(int)\n",
    "\n",
    "    days = np.sort(d[\"day\"].unique())\n",
    "    data = [d.loc[d[\"day\"] == day, metric].dropna().to_numpy() for day in days]\n",
    "\n",
    "    plt.figure(figsize=(10, 3.8))\n",
    "    plt.boxplot(\n",
    "        data,\n",
    "        labels=days,\n",
    "        showfliers=False,     # hide extreme points (cleaner); set True if you want\n",
    "        whis=1.5\n",
    "    )\n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.ylabel(\"Plateau duration (min)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _heatmap_plateau(df_daily: pd.DataFrame, title: str, zscore_within_animal: bool = True):\n",
    "    mat = df_daily.pivot_table(index=\"animal_id\", columns=\"day\", values=\"plateau_duration_min\", aggfunc=\"mean\")\n",
    "    if zscore_within_animal:\n",
    "        mat = mat.sub(mat.mean(axis=1), axis=0)\n",
    "        mat = mat.div(mat.std(axis=1).replace(0, np.nan), axis=0)\n",
    "\n",
    "    peak_day = mat.idxmax(axis=1)\n",
    "    mat = mat.loc[peak_day.sort_values().index]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    im = plt.imshow(mat.values, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.ylabel(\"Animal (sorted by peak day)\")\n",
    "    plt.title(title + (\" (z-score within animal)\" if zscore_within_animal else \"\"))\n",
    "    plt.xticks(np.arange(mat.shape[1]), mat.columns.astype(int))\n",
    "    plt.yticks([])\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\"Plateau duration (z)\" if zscore_within_animal else \"Plateau duration (min)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# SMARR: per-female per-day plateau_duration\n",
    "# ----------------------------\n",
    "def smarr_daily_plateau(df_smarr: pd.DataFrame, dealign: bool = False, q: int = Q_THRESH) -> pd.DataFrame:\n",
    "    female_cols = [c for c in df_smarr.columns if str(c).lower().startswith(\"fem\")]\n",
    "    if len(female_cols) == 0:\n",
    "        raise ValueError(\"Smarr: No female columns found (expected columns starting with 'fem').\")\n",
    "\n",
    "    X = df_smarr[female_cols].to_numpy().T  # (n_females, n_timepoints)\n",
    "    n_fem, n_tp = X.shape\n",
    "    n_days = n_tp // SMARR_MIN_PER_DAY\n",
    "    if n_days < 1:\n",
    "        raise ValueError(\"Smarr: Not enough data for at least 1 full day.\")\n",
    "\n",
    "    X = X[:, :n_days * SMARR_MIN_PER_DAY]\n",
    "    n_tp = X.shape[1]\n",
    "\n",
    "    # \"maximally misaligned\": roll each female by i days (mod total length)\n",
    "    if dealign:\n",
    "        Xm = np.empty_like(X)\n",
    "        for i in range(n_fem):\n",
    "            shift = (i * SMARR_MIN_PER_DAY) % n_tp\n",
    "            Xm[i] = np.roll(X[i], -shift)\n",
    "        X = Xm\n",
    "\n",
    "    # per-female threshold from ALL dark-phase minutes across window\n",
    "    thresholds = np.zeros(n_fem, dtype=float)\n",
    "    for i in range(n_fem):\n",
    "        dark_vals = []\n",
    "        for d in range(n_days):\n",
    "            day_slice = X[i, d*SMARR_MIN_PER_DAY:(d+1)*SMARR_MIN_PER_DAY]\n",
    "            dark_vals.append(day_slice[SMARR_DARK_START:SMARR_DARK_END])\n",
    "        thresholds[i] = float(np.nanpercentile(np.concatenate(dark_vals), q))\n",
    "\n",
    "    rows = []\n",
    "    for i in range(n_fem):\n",
    "        thr = thresholds[i]\n",
    "        for d in range(n_days):\n",
    "            day_slice = X[i, d*SMARR_MIN_PER_DAY:(d+1)*SMARR_MIN_PER_DAY]\n",
    "            dark = day_slice[SMARR_DARK_START:SMARR_DARK_END]\n",
    "            plateau_duration = int(np.sum(dark >= thr))  # minutes\n",
    "            rows.append({\"animal_id\": i, \"day\": d + 1, \"plateau_duration_min\": plateau_duration})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ----------------------------\n",
    "# JAX: pull from ACTIVITY_CACHE and compute per-animal per-day plateau_duration\n",
    "# ----------------------------\n",
    "def _get_jax_loaded_df_for_rep(rep_label: str, cfg: dict) -> pd.DataFrame:\n",
    "    if \"ACTIVITY_CACHE\" not in globals():\n",
    "        raise ValueError(\"JAX: ACTIVITY_CACHE not found. Run your JAX loading cell first so data are cached.\")\n",
    "\n",
    "    parts = []\n",
    "    for cage_id in cfg[\"cages\"]:\n",
    "        key = (cage_id, cfg[\"start\"], cfg[\"end\"])\n",
    "        if key not in ACTIVITY_CACHE:\n",
    "            raise ValueError(f\"JAX: Missing cached data for key={key}. Load it first with your loader.\")\n",
    "        df = ACTIVITY_CACHE[key].copy()\n",
    "        df[\"cage_id\"] = cage_id\n",
    "        df[\"rep\"] = rep_label\n",
    "        parts.append(df)\n",
    "\n",
    "    out = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=[\"time\",\"animal_id\",\"value\",\"cage_id\",\"rep\"])\n",
    "    out[\"time\"] = pd.to_datetime(out[\"time\"])\n",
    "    return out\n",
    "\n",
    "def jax_daily_plateau(rep_label: str, cfg: dict, q: int = Q_THRESH) -> pd.DataFrame:\n",
    "    df = _get_jax_loaded_df_for_rep(rep_label, cfg)\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"JAX: No cached data found for {rep_label}.\")\n",
    "\n",
    "    baseline = pd.to_datetime(cfg[\"start\"])\n",
    "    dt_minutes = ((df[\"time\"] - baseline).dt.total_seconds() / 60.0).astype(int)\n",
    "    df = df.assign(\n",
    "        minute_from_start=dt_minutes,\n",
    "        day=(dt_minutes // JAX_MIN_PER_DAY) + 1,\n",
    "        minute_in_day=dt_minutes % JAX_MIN_PER_DAY\n",
    "    )\n",
    "\n",
    "    df_dark = df[(df[\"minute_in_day\"] >= JAX_DARK_START) & (df[\"minute_in_day\"] < JAX_DARK_END)].copy()\n",
    "\n",
    "    thr = df_dark.groupby(\"animal_id\")[\"value\"].apply(lambda s: float(np.nanpercentile(s.to_numpy(), q)))\n",
    "    df_dark = df_dark.join(thr.rename(\"thr\"), on=\"animal_id\")\n",
    "\n",
    "    df_daily = (\n",
    "        df_dark.assign(above=lambda d: d[\"value\"] >= d[\"thr\"])\n",
    "        .groupby([\"animal_id\", \"day\"], as_index=False)[\"above\"]\n",
    "        .sum()\n",
    "        .rename(columns={\"above\": \"plateau_duration_min\"})\n",
    "    )\n",
    "    df_daily[\"rep\"] = rep_label\n",
    "    return df_daily\n",
    "\n",
    "# ============================================================\n",
    "# RUN: SMARR (aligned + misaligned)\n",
    "# ============================================================\n",
    "df_smarr = pd.read_csv(\"mice data.xlsx - FemAct (1).csv\")\n",
    "\n",
    "smarr_aligned_daily = smarr_daily_plateau(df_smarr, dealign=False, q=Q_THRESH)\n",
    "smarr_misaligned_daily = smarr_daily_plateau(df_smarr, dealign=True, q=Q_THRESH)\n",
    "\n",
    "print(\"\\n=== Smarr ALIGNED rankings ===\")\n",
    "print(_rank_days(smarr_aligned_daily).to_string(index=False))\n",
    "print(\"\\n=== Smarr MISALIGNED rankings ===\")\n",
    "print(_rank_days(smarr_misaligned_daily).to_string(index=False))\n",
    "\n",
    "_boxplot_by_day(smarr_aligned_daily, f\"Smarr ALIGNED — Plateau duration by day (boxplots, q={Q_THRESH})\")\n",
    "_boxplot_by_day(smarr_misaligned_daily, f\"Smarr MISALIGNED — Plateau duration by day (boxplots, q={Q_THRESH})\")\n",
    "\n",
    "_heatmap_plateau(smarr_aligned_daily, f\"Smarr ALIGNED — Per-female plateau duration (q={Q_THRESH})\", zscore_within_animal=True)\n",
    "_heatmap_plateau(smarr_misaligned_daily, f\"Smarr MISALIGNED — Per-female plateau duration (q={Q_THRESH})\", zscore_within_animal=True)\n",
    "\n",
    "# ============================================================\n",
    "# RUN: JAX Rep1 + Rep2 (ASSUMES already loaded/cached in ACTIVITY_CACHE)\n",
    "# ============================================================\n",
    "rep1_daily = jax_daily_plateau(\"Rep1\", VEHICLE_CAGES[\"Rep1\"], q=Q_THRESH)\n",
    "rep2_daily = jax_daily_plateau(\"Rep2\", VEHICLE_CAGES[\"Rep2\"], q=Q_THRESH)\n",
    "\n",
    "print(\"\\n=== JAX Rep1 rankings ===\")\n",
    "print(_rank_days(rep1_daily).to_string(index=False))\n",
    "print(\"\\n=== JAX Rep2 rankings ===\")\n",
    "print(_rank_days(rep2_daily).to_string(index=False))\n",
    "\n",
    "_boxplot_by_day(rep1_daily, f\"JAX Rep1 (Vehicle) — Plateau duration by day (boxplots, q={Q_THRESH})\")\n",
    "_boxplot_by_day(rep2_daily, f\"JAX Rep2 (Vehicle) — Plateau duration by day (boxplots, q={Q_THRESH})\")\n",
    "\n",
    "_heatmap_plateau(rep1_daily, f\"JAX Rep1 (Vehicle) — Per-animal plateau duration (q={Q_THRESH})\", zscore_within_animal=True)\n",
    "_heatmap_plateau(rep2_daily, f\"JAX Rep2 (Vehicle) — Per-animal plateau duration (q={Q_THRESH})\", zscore_within_animal=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3e3e5-e8fb-4bfc-afc3-f731de67cbcb",
   "metadata": {},
   "source": [
    "## 5. Top-k vs Rest Permutation Test\n",
    "\n",
    "Test statistic:\n",
    "T = mean(top-k days) − mean(other days)\n",
    "\n",
    "Permutation procedure:\n",
    "- Shuffle day labels within animal\n",
    "- Recompute T\n",
    "- Repeat N times\n",
    "- Compute empirical p-value\n",
    "\n",
    "Purpose:\n",
    "Determine whether top-ranked days significantly deviate from baseline structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ecfd0-8d1b-4b23-a2d4-48e1e61be7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# TOP-3 DAYS VS REST PERMUTATION TEST (JAX Rep1 + Rep2)\n",
    "#\n",
    "# Requires:\n",
    "#   rep1_daily, rep2_daily\n",
    "# each with columns:\n",
    "#   animal_id, day, plateau_duration_min\n",
    "#\n",
    "# Null: day labels are exchangeable WITHIN each animal.\n",
    "# Permutation: shuffle day labels within each animal (plateau durations fixed).\n",
    "#\n",
    "# Statistic:\n",
    "#   Let m_d = mean plateau_duration_min across animals on day d.\n",
    "#   T = mean(top 3 of {m_d}) - mean(rest of {m_d})\n",
    "# ============================================================\n",
    "\n",
    "RNG_SEED = 0\n",
    "N_PERM = 10000\n",
    "K = 3\n",
    "\n",
    "def day_mean_vector(df_daily: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Day-level mean plateau duration across animals, indexed by day.\"\"\"\n",
    "    return df_daily.groupby(\"day\")[\"plateau_duration_min\"].mean().sort_index()\n",
    "\n",
    "def topk_vs_rest_stat(day_means: pd.Series, k: int = 3) -> float:\n",
    "    vals = day_means.to_numpy(dtype=float)\n",
    "    if len(vals) <= k:\n",
    "        return float(\"nan\")\n",
    "    order = np.argsort(vals)  # ascending\n",
    "    topk = vals[order][-k:]\n",
    "    rest = vals[order][:-k]\n",
    "    return float(topk.mean() - rest.mean())\n",
    "\n",
    "def permute_days_within_animal(df_daily: pd.DataFrame, rng: np.random.Generator) -> pd.DataFrame:\n",
    "    parts = []\n",
    "    for _, g in df_daily.groupby(\"animal_id\", sort=False):\n",
    "        g2 = g.copy()\n",
    "        g2[\"day\"] = rng.permutation(g2[\"day\"].to_numpy())\n",
    "        parts.append(g2)\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "def permutation_test_top3_vs_rest(\n",
    "    df_daily: pd.DataFrame,\n",
    "    label: str,\n",
    "    k: int = 3,\n",
    "    n_perm: int = 10000,\n",
    "    seed: int = 0,\n",
    "    plot: bool = True,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Observed\n",
    "    dm_obs = day_mean_vector(df_daily)\n",
    "    T_obs = topk_vs_rest_stat(dm_obs, k=k)\n",
    "\n",
    "    # Permutations\n",
    "    T_perm = np.empty(n_perm, dtype=float)\n",
    "    for i in range(n_perm):\n",
    "        perm_df = permute_days_within_animal(df_daily, rng)\n",
    "        dm = day_mean_vector(perm_df)\n",
    "        T_perm[i] = topk_vs_rest_stat(dm, k=k)\n",
    "\n",
    "    # One-sided p-value (large = more \"structured\" / more top-heavy)\n",
    "    p_val = (np.sum(T_perm >= T_obs) + 1) / (n_perm + 1)\n",
    "\n",
    "    # Print summary + which days are top-3 in observed data\n",
    "    top3_days = dm_obs.sort_values(ascending=False).head(k)\n",
    "    print(\"\\n\" + \"=\" * 72)\n",
    "    print(f\"{label}: Top-{k} days vs rest permutation test\")\n",
    "    print(f\"Observed statistic T = mean(top-{k} day means) - mean(rest day means)\")\n",
    "    print(f\"Observed top-{k} days (by day mean plateau duration):\")\n",
    "    for d, v in top3_days.items():\n",
    "        print(f\"  Day {int(d)}: mean plateau duration = {v:.3f} min\")\n",
    "    print(f\"Observed T: {T_obs:.6f}\")\n",
    "    print(f\"Permutation p-value: {p_val:.6g}\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "    if plot:\n",
    "        # Null distribution\n",
    "        plt.figure(figsize=(8, 3.6))\n",
    "        plt.hist(T_perm, bins=40)\n",
    "        plt.axvline(T_obs, linestyle=\"--\", linewidth=2, label=\"Observed T\")\n",
    "        plt.title(f\"{label}: Null distribution (Top-{k} vs rest)\")\n",
    "        plt.xlabel(\"Permutation statistic T\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Observed day means with top-k highlighted\n",
    "        plt.figure(figsize=(10, 3.6))\n",
    "        x = dm_obs.index.to_numpy()\n",
    "        y = dm_obs.to_numpy()\n",
    "        plt.plot(x, y, linewidth=2, label=\"Day mean plateau duration\")\n",
    "        for d in top3_days.index:\n",
    "            plt.axvline(int(d), linestyle=\"--\", linewidth=1.3, alpha=0.8)\n",
    "        plt.title(f\"{label}: Observed day means (Top-{k} highlighted)\")\n",
    "        plt.xlabel(\"Day\")\n",
    "        plt.ylabel(\"Mean plateau duration (min)\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"k\": k,\n",
    "        \"T_obs\": T_obs,\n",
    "        \"p_value\": p_val,\n",
    "        \"T_perm\": T_perm,\n",
    "        \"day_means_obs\": dm_obs,\n",
    "        \"topk_days_obs\": top3_days,\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# RUN ON REP1 + REP2\n",
    "# ============================================================\n",
    "res_rep1_top3 = permutation_test_top3_vs_rest(\n",
    "    rep1_daily, label=\"JAX Rep1\", k=K, n_perm=N_PERM, seed=RNG_SEED, plot=True\n",
    ")\n",
    "\n",
    "res_rep2_top3 = permutation_test_top3_vs_rest(\n",
    "    rep2_daily, label=\"JAX Rep2\", k=K, n_perm=N_PERM, seed=RNG_SEED, plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a603e01-ff7a-48a1-8550-4dfa991f470b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f66fef9-4b95-4962-affd-922a196cda23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

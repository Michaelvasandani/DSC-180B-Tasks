{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morph2REP Estrous Cycle Detection via Wavelet Analysis\n",
    "## Calendar Day Alignment (No Time Shift)\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook applies the Smarr et al. (2017) wavelet-based estrous detection method to Morph2REP Study 1001 vehicle-treated female mice.\n",
    "\n",
    "### Time Alignment Decision\n",
    "\n",
    "Smarr et al. aligned their analysis to circadian time (CT), starting each day at lights-off (6PM). However, we chose to use **calendar day alignment** (midnight to midnight) for the following reasons:\n",
    "\n",
    "1. **Simplicity**: Direct mapping between analysis days and calendar dates makes interpretation straightforward\n",
    "2. **Treatment alignment**: Dosing and cage changes are recorded in calendar time, making it easier to relate findings to experimental events\n",
    "3. **Daily averaging**: Since we compute daily mean ultradian power (averaging across 24h), the specific hour boundaries matter less than for hour-by-hour analyses\n",
    "4. **Data preservation**: Time shifting created artificial \"empty\" days due to recording end times, losing usable data\n",
    "\n",
    "### Analysis Pipeline\n",
    "1. **Data Loading** - Load locomotion bout data from S3\n",
    "2. **Data Quality EDA** - Identify incomplete recording days\n",
    "3. **Wavelet Analysis** - Compute ultradian power and detect LOW days\n",
    "4. **Visualization** - Display results with treatment schedule overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import duckdb\n",
    "from datetime import date, datetime, timedelta\n",
    "from scipy.signal import cwt, morlet2\n",
    "from scipy.stats import wilcoxon, chisquare\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Constants\n",
    "MINUTES_PER_DAY = 1440\n",
    "PERIODS_MINUTES = np.logspace(np.log10(60), np.log10(39*60), 50)\n",
    "PERIODS_HOURS = PERIODS_MINUTES / 60\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STUDY CONFIGURATION - CALENDAR DAY ALIGNMENT\n",
    "# =============================================================================\n",
    "\n",
    "S3_BASE = \"s3://jax-envision-public-data/study_1001/2025v3.3/tabular\"\n",
    "\n",
    "# Vehicle-treated cages with full experimental timeline\n",
    "# Using CALENDAR DAYS (midnight to midnight)\n",
    "VEHICLE_CAGES = {\n",
    "    \"Rep1\": {\n",
    "        \"cages\": [4918, 4922, 4923],\n",
    "        \"analysis_start\": \"2025-01-07\",\n",
    "        \"analysis_end\": \"2025-01-22\",\n",
    "        \"n_days\": 16,\n",
    "        \"valid_days\": (2, 16),  # Day 1 partial (starts 22:00), Day 16 partial but usable (13h)\n",
    "        # Treatment schedule\n",
    "        \"dose_1\": datetime(2025, 1, 14, 6, 0),\n",
    "        \"dose_2\": datetime(2025, 1, 17, 17, 0),\n",
    "        \"cage_change\": datetime(2025, 1, 15, 12, 0),\n",
    "    },\n",
    "    \"Rep2\": {\n",
    "        \"cages\": [4928, 4929, 4934],\n",
    "        \"analysis_start\": \"2025-01-22\",\n",
    "        \"analysis_end\": \"2025-02-04\",\n",
    "        \"n_days\": 14,\n",
    "        \"valid_days\": (2, 14),  # Day 1 partial (starts 14:00), Day 14 complete\n",
    "        # Treatment schedule\n",
    "        \"dose_1\": datetime(2025, 1, 28, 17, 0),\n",
    "        \"dose_2\": datetime(2025, 1, 31, 6, 0),\n",
    "        \"cage_change\": datetime(2025, 1, 29, 12, 0),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Calculate day numbers for treatment events (calendar days)\n",
    "for rep, cfg in VEHICLE_CAGES.items():\n",
    "    start = pd.to_datetime(cfg['analysis_start'])\n",
    "    cfg['dose_1_day'] = (cfg['dose_1'].date() - start.date()).days + 1\n",
    "    cfg['dose_2_day'] = (cfg['dose_2'].date() - start.date()).days + 1\n",
    "    cfg['cage_change_day'] = (cfg['cage_change'].date() - start.date()).days + 1\n",
    "\n",
    "print(\"Study Configuration (Calendar Day Alignment):\")\n",
    "print(\"=\"*60)\n",
    "for rep, cfg in VEHICLE_CAGES.items():\n",
    "    print(f\"\\n{rep}:\")\n",
    "    print(f\"  Date range: {cfg['analysis_start']} to {cfg['analysis_end']}\")\n",
    "    print(f\"  Total days: {cfg['n_days']}, Valid for analysis: Days {cfg['valid_days'][0]}-{cfg['valid_days'][1]}\")\n",
    "    print(f\"  Cages: {cfg['cages']}\")\n",
    "    print(f\"  Dose 1: Day {cfg['dose_1_day']} ({cfg['dose_1'].strftime('%b %d, %I:%M %p')})\")\n",
    "    print(f\"  Dose 2: Day {cfg['dose_2_day']} ({cfg['dose_2'].strftime('%b %d, %I:%M %p')})\")\n",
    "    print(f\"  Cage change: Day {cfg['cage_change_day']} ({cfg['cage_change'].strftime('%b %d, %I:%M %p')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# WAVELET FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def compute_wavelet_transform(data, periods_minutes=None, w=5):\n",
    "    \"\"\"\n",
    "    Compute continuous wavelet transform using Morlet wavelet.\n",
    "    \"\"\"\n",
    "    data = pd.Series(data).interpolate().bfill().ffill().fillna(0).values\n",
    "    \n",
    "    if periods_minutes is None:\n",
    "        periods_minutes = PERIODS_MINUTES\n",
    "    \n",
    "    fs = 1\n",
    "    scales = periods_minutes * fs * w / (2 * np.pi)\n",
    "    \n",
    "    coeffs = cwt(data, morlet2, scales, w=w)\n",
    "    power = np.abs(coeffs)**2\n",
    "    \n",
    "    return power, periods_minutes\n",
    "\n",
    "\n",
    "def extract_band_power(power, periods_minutes, band_hours):\n",
    "    \"\"\"\n",
    "    Extract MAX power in a frequency band.\n",
    "    \"\"\"\n",
    "    periods_hours = periods_minutes / 60\n",
    "    band_mask = (periods_hours >= band_hours[0]) & (periods_hours <= band_hours[1])\n",
    "    \n",
    "    if not np.any(band_mask):\n",
    "        return np.zeros(power.shape[1])\n",
    "    \n",
    "    band_power = np.max(power[band_mask, :], axis=0)\n",
    "    return band_power\n",
    "\n",
    "\n",
    "def bouts_to_minute_counts_calendar(bout_df, start_date, n_days):\n",
    "    \"\"\"\n",
    "    Convert bout data to minute-level counts using CALENDAR days.\n",
    "    Start time = midnight on start_date.\n",
    "    \"\"\"\n",
    "    bout_df = bout_df.copy()\n",
    "    start_time = pd.to_datetime(start_date + \" 00:00:00\")  # Midnight\n",
    "    n_minutes = n_days * MINUTES_PER_DAY\n",
    "    \n",
    "    bout_df['minutes_from_start'] = (bout_df['start_time'] - start_time).dt.total_seconds() / 60\n",
    "    bout_df = bout_df[(bout_df['minutes_from_start'] >= 0) & (bout_df['minutes_from_start'] < n_minutes)]\n",
    "    bout_df['minute_bin'] = bout_df['minutes_from_start'].astype(int)\n",
    "    \n",
    "    counts = bout_df.groupby('minute_bin').size()\n",
    "    \n",
    "    full_series = pd.Series(index=range(n_minutes), dtype=float).fillna(0)\n",
    "    full_series.update(counts)\n",
    "    \n",
    "    return full_series.values\n",
    "\n",
    "\n",
    "print(\"Wavelet functions defined (using calendar day alignment).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def load_parquet_s3(cage_id, start_date, end_date, table_name):\n",
    "    \"\"\"Load parquet data from S3 for a specific cage and date range.\"\"\"\n",
    "    conn = duckdb.connect()\n",
    "    conn.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "    conn.execute(\"SET s3_region='us-east-1';\")\n",
    "    \n",
    "    dates = pd.date_range(start_date, end_date, freq='D')\n",
    "    all_data = []\n",
    "    \n",
    "    for d in dates:\n",
    "        date_str = d.strftime('%Y-%m-%d')\n",
    "        path = f\"{S3_BASE}/cage_id={cage_id}/date={date_str}/{table_name}\"\n",
    "        try:\n",
    "            df = conn.execute(f\"SELECT * FROM read_parquet('{path}')\").fetchdf()\n",
    "            df['cage_id'] = cage_id\n",
    "            df['date'] = date_str\n",
    "            all_data.append(df)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    conn.close()\n",
    "    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "\n",
    "print(\"Load function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD LOCOMOTION BOUT DATA\n",
    "# =============================================================================\n",
    "print(\"Loading Morph2REP Locomotion Bout Data...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_bouts = []\n",
    "for rep, cfg in VEHICLE_CAGES.items():\n",
    "    print(f\"\\n{rep} ({cfg['n_days']} days):\")\n",
    "    for cage_id in cfg['cages']:\n",
    "        print(f\"  Cage {cage_id}...\", end=\" \")\n",
    "        df = load_parquet_s3(cage_id, cfg['analysis_start'], cfg['analysis_end'], 'animal_bouts.parquet')\n",
    "        if len(df) > 0:\n",
    "            df['replicate'] = rep\n",
    "            all_bouts.append(df)\n",
    "            print(f\"{len(df):,} rows\")\n",
    "        else:\n",
    "            print(\"No data\")\n",
    "\n",
    "df_bouts = pd.concat(all_bouts, ignore_index=True)\n",
    "print(f\"\\nTotal bout rows: {len(df_bouts):,}\")\n",
    "\n",
    "# Filter for locomotion bouts\n",
    "df_loco = df_bouts[df_bouts['state_name'] == 'animal_bouts.locomotion'].copy()\n",
    "df_loco['start_time'] = pd.to_datetime(df_loco['start_time'])\n",
    "\n",
    "print(f\"\\nLocomotion bouts: {len(df_loco):,}\")\n",
    "for rep in ['Rep1', 'Rep2']:\n",
    "    rep_df = df_loco[df_loco['replicate'] == rep]\n",
    "    print(f\"  {rep}: {len(rep_df):,} bouts, {rep_df['animal_id'].nunique()} animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Data Quality EDA\n",
    "\n",
    "Check for incomplete recording days using calendar day boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHECK DATA COMPLETENESS BY CALENDAR DAY\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"DATA COMPLETENESS CHECK (Calendar Days)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for rep, cfg in VEHICLE_CAGES.items():\n",
    "    print(f\"\\n{rep}:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    rep_df = df_loco[df_loco['replicate'] == rep].copy()\n",
    "    rep_df['calendar_date'] = rep_df['start_time'].dt.date\n",
    "    \n",
    "    # Count bouts per calendar day\n",
    "    daily_counts = rep_df.groupby('calendar_date').agg({\n",
    "        'start_time': ['count', 'min', 'max']\n",
    "    })\n",
    "    daily_counts.columns = ['bout_count', 'first_bout', 'last_bout']\n",
    "    daily_counts = daily_counts.sort_index()\n",
    "    \n",
    "    median_count = daily_counts['bout_count'].median()\n",
    "    \n",
    "    print(f\"\\n{'Day':<5} {'Date':<12} {'Bouts':<10} {'First':<10} {'Last':<10} {'Hours':<8} {'Status'}\")\n",
    "    print(\"-\"*75)\n",
    "    \n",
    "    for i, (date, row) in enumerate(daily_counts.iterrows()):\n",
    "        day_num = i + 1\n",
    "        first_hour = row['first_bout'].hour\n",
    "        last_hour = row['last_bout'].hour\n",
    "        hours_covered = last_hour - first_hour + 1\n",
    "        \n",
    "        # Determine status\n",
    "        if row['bout_count'] < median_count * 0.5:\n",
    "            status = \"⚠️ LOW COUNT\"\n",
    "        elif first_hour > 6:\n",
    "            status = f\"⚠️ LATE START ({first_hour}:00)\"\n",
    "        elif last_hour < 18:\n",
    "            status = f\"⚠️ EARLY END ({last_hour}:00)\"\n",
    "        else:\n",
    "            status = \"✓ Complete\"\n",
    "            \n",
    "        print(f\"D{day_num:<4} {str(date):<12} {int(row['bout_count']):<10} {first_hour:02d}:00{'':<5} {last_hour:02d}:59{'':<5} ~{hours_covered:<6} {status}\")\n",
    "    \n",
    "    print(f\"\\nMedian daily bout count: {median_count:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHECK CAGE-LEVEL DATA FOR PROBLEMATIC DAYS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CAGE-LEVEL CHECK FOR POTENTIALLY PROBLEMATIC DAYS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Rep2 Day 14 - check for missing cage\n",
    "print(\"\\nRep2 - Checking all days by cage:\")\n",
    "rep2_df = df_loco[df_loco['replicate'] == 'Rep2'].copy()\n",
    "rep2_df['calendar_date'] = rep2_df['start_time'].dt.date\n",
    "\n",
    "dates = sorted(rep2_df['calendar_date'].unique())\n",
    "cages = VEHICLE_CAGES['Rep2']['cages']\n",
    "\n",
    "print(f\"\\n{'Day':<5}\", end=\"\")\n",
    "for cage in cages:\n",
    "    print(f\"Cage {cage:<10}\", end=\"\")\n",
    "print(\"Status\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, d in enumerate(dates):\n",
    "    day_num = i + 1\n",
    "    print(f\"D{day_num:<4}\", end=\"\")\n",
    "    cage_counts = []\n",
    "    for cage in cages:\n",
    "        count = len(rep2_df[(rep2_df['calendar_date'] == d) & (rep2_df['cage_id'] == cage)])\n",
    "        cage_counts.append(count)\n",
    "        flag = \"⚠️\" if count < 1000 else \"\"\n",
    "        print(f\"{count:<14}{flag}\", end=\"\")\n",
    "    \n",
    "    if any(c == 0 for c in cage_counts):\n",
    "        print(\"MISSING CAGE\")\n",
    "    elif any(c < 1000 for c in cage_counts):\n",
    "        print(\"LOW COUNT\")\n",
    "    else:\n",
    "        print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE DATA COMPLETENESS\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for col, (rep, cfg) in enumerate(VEHICLE_CAGES.items()):\n",
    "    ax = axes[col]\n",
    "    \n",
    "    rep_df = df_loco[df_loco['replicate'] == rep].copy()\n",
    "    rep_df['calendar_date'] = rep_df['start_time'].dt.date\n",
    "    \n",
    "    daily_counts = rep_df.groupby('calendar_date').size()\n",
    "    days = list(range(1, len(daily_counts) + 1))\n",
    "    counts = daily_counts.values\n",
    "    \n",
    "    # Determine valid days\n",
    "    valid_start, valid_end = cfg['valid_days']\n",
    "    \n",
    "    # Color bars based on validity\n",
    "    colors = []\n",
    "    for i, c in enumerate(counts):\n",
    "        day_num = i + 1\n",
    "        if day_num < valid_start:\n",
    "            colors.append('red')  # Excluded (partial start)\n",
    "        elif day_num > valid_end:\n",
    "            colors.append('red')  # Excluded\n",
    "        else:\n",
    "            colors.append('green')  # Valid\n",
    "    \n",
    "    ax.bar(days, counts, color=colors, edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    # Mark treatment days\n",
    "    ax.axvline(x=cfg['dose_1_day'], color='purple', linestyle='-', linewidth=2.5, alpha=0.8, label='Dose 1/2')\n",
    "    ax.axvline(x=cfg['dose_2_day'], color='purple', linestyle='-', linewidth=2.5, alpha=0.8)\n",
    "    ax.axvline(x=cfg['cage_change_day'], color='orange', linestyle='--', linewidth=2, alpha=0.8, label='Cage Change')\n",
    "    \n",
    "    # Add date labels\n",
    "    date_labels = [d.strftime('%b %d') for d in daily_counts.index]\n",
    "    ax.set_xticks(days)\n",
    "    ax.set_xticklabels(date_labels, rotation=45, ha='right', fontsize=8)\n",
    "    \n",
    "    ax.set_xlabel('Date (Calendar Day)', fontsize=11)\n",
    "    ax.set_ylabel('Locomotion Bout Count', fontsize=11)\n",
    "    ax.set_title(f'{rep}: Daily Bout Counts (Calendar Days)\\nGreen = Valid, Red = Excluded', fontsize=12)\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('morph2rep_calendar_data_completeness.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Summary\n",
    "\n",
    "Using calendar day alignment:\n",
    "\n",
    "**Rep1 (Jan 7-22):**\n",
    "- **Day 1 (Jan 7):** Recording started at 22:00 - only 2 hours → **EXCLUDE**\n",
    "- **Days 2-15 (Jan 8-21):** Complete 24-hour recordings → **VALID**\n",
    "- **Day 16 (Jan 22):** Recording ended at 12:59 - 13 hours → **VALID** (sufficient for daily average)\n",
    "\n",
    "**Rep2 (Jan 22 - Feb 4):**\n",
    "- **Day 1 (Jan 22):** Recording started at 14:00 - only 10 hours → **EXCLUDE**\n",
    "- **Days 2-14 (Jan 23 - Feb 4):** Complete recordings → **VALID**\n",
    "\n",
    "**Note:** Unlike the time-shifted approach, we can include Day 16 for Rep1 since it has 13 hours of data, sufficient for computing daily mean ultradian power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Wavelet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# WAVELET ANALYSIS - CALENDAR DAY ALIGNMENT\n",
    "# =============================================================================\n",
    "\n",
    "all_rep_results = {}\n",
    "\n",
    "for rep, cfg in VEHICLE_CAGES.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{rep} WAVELET ANALYSIS (Calendar Days)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    rep_df = df_loco[df_loco['replicate'] == rep].copy()\n",
    "    animals = sorted([a for a in rep_df['animal_id'].unique() if a != 0])\n",
    "    valid_days = cfg['valid_days']\n",
    "    \n",
    "    print(f\"Animals: {len(animals)}\")\n",
    "    print(f\"Total days: {cfg['n_days']}, Valid for analysis: Days {valid_days[0]}-{valid_days[1]}\")\n",
    "    \n",
    "    # Compute wavelet for each animal\n",
    "    animal_results = []\n",
    "    \n",
    "    for animal_id in animals:\n",
    "        animal_df = rep_df[rep_df['animal_id'] == animal_id].copy()\n",
    "        cage_id = animal_df['cage_id'].iloc[0]\n",
    "        \n",
    "        # Convert bouts to minute counts (calendar alignment)\n",
    "        animal_ts = bouts_to_minute_counts_calendar(animal_df, cfg['analysis_start'], cfg['n_days'])\n",
    "        \n",
    "        # Compute wavelet\n",
    "        power, _ = compute_wavelet_transform(animal_ts, PERIODS_MINUTES)\n",
    "        ultradian = extract_band_power(power, PERIODS_MINUTES, (1, 3))\n",
    "        \n",
    "        # Day-by-day power (calendar days)\n",
    "        day_powers = []\n",
    "        for day in range(1, cfg['n_days'] + 1):\n",
    "            day_start = (day - 1) * MINUTES_PER_DAY\n",
    "            day_end = day * MINUTES_PER_DAY\n",
    "            if day_end <= len(ultradian):\n",
    "                day_powers.append(np.nanmean(ultradian[day_start:day_end]))\n",
    "            else:\n",
    "                day_powers.append(np.nan)\n",
    "        \n",
    "        animal_results.append({\n",
    "            'animal_id': animal_id,\n",
    "            'cage_id': cage_id,\n",
    "            'day_powers': day_powers,\n",
    "            'n_days': cfg['n_days'],\n",
    "            'ultradian_ts': ultradian\n",
    "        })\n",
    "    \n",
    "    # =========================================================================\n",
    "    # DAY-BY-DAY TABLE\n",
    "    # =========================================================================\n",
    "    print(f\"\\n--- Day-by-Day Ultradian Power ---\")\n",
    "    \n",
    "    # Header\n",
    "    header = f\"{'Animal':<10} {'Cage':<8}\"\n",
    "    for d in range(1, cfg['n_days'] + 1):\n",
    "        marker = \"*\" if d < valid_days[0] or d > valid_days[1] else \"\"\n",
    "        header += f\"D{d}{marker:<5}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    \n",
    "    for r in animal_results:\n",
    "        row = f\"{r['animal_id']:<10} {r['cage_id']:<8}\"\n",
    "        for d in range(1, cfg['n_days'] + 1):\n",
    "            val = r['day_powers'][d-1]\n",
    "            row += f\"{val:<7.1f}\" if not np.isnan(val) else f\"{'N/A':<7}\"\n",
    "        print(row)\n",
    "    \n",
    "    print(f\"\\n* = Excluded from analysis\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LOW DAY DETECTION\n",
    "    # =========================================================================\n",
    "    print(f\"\\n--- LOW Days Detection (Days {valid_days[0]}-{valid_days[1]}) ---\")\n",
    "    \n",
    "    threshold_pct = 0.80\n",
    "    \n",
    "    print(f\"\\n{'Animal':<10} {'Cage':<8} {'LOW days':<25} {'Spacings':<20} {'4-day cycle?'}\")\n",
    "    print(\"-\"*90)\n",
    "    \n",
    "    cycle_results = []\n",
    "    \n",
    "    for r in animal_results:\n",
    "        animal_id = r['animal_id']\n",
    "        cage_id = r['cage_id']\n",
    "        day_powers = r['day_powers']\n",
    "        \n",
    "        # Calculate median using only valid days\n",
    "        valid_powers = [day_powers[i] for i in range(valid_days[0]-1, valid_days[1])\n",
    "                        if i < len(day_powers) and not np.isnan(day_powers[i])]\n",
    "        \n",
    "        if not valid_powers:\n",
    "            continue\n",
    "        \n",
    "        median_power = np.median(valid_powers)\n",
    "        threshold = median_power * threshold_pct\n",
    "        \n",
    "        # Find LOW days (only within valid range)\n",
    "        low_days = []\n",
    "        for day in range(valid_days[0], valid_days[1] + 1):\n",
    "            idx = day - 1\n",
    "            if idx < len(day_powers) and not np.isnan(day_powers[idx]) and day_powers[idx] < threshold:\n",
    "                low_days.append(day)\n",
    "        \n",
    "        # Calculate spacings\n",
    "        spacings = [low_days[i] - low_days[i-1] for i in range(1, len(low_days))]\n",
    "        \n",
    "        # Check for 4-day pattern\n",
    "        has_exact_4 = any(d2 - d1 == 4 for d1 in low_days for d2 in low_days if d2 > d1)\n",
    "        has_approx_4 = any(3 <= d2 - d1 <= 5 for d1 in low_days for d2 in low_days if d2 > d1)\n",
    "        \n",
    "        if len(low_days) >= 2 and has_exact_4:\n",
    "            assessment = \"✓ STRONG\"\n",
    "        elif len(low_days) >= 2 and has_approx_4:\n",
    "            assessment = \"~ MODERATE\"\n",
    "        elif len(low_days) >= 2:\n",
    "            assessment = \"? IRREGULAR\"\n",
    "        else:\n",
    "            assessment = \"✗ INSUFFICIENT\"\n",
    "        \n",
    "        cycle_results.append({\n",
    "            'animal_id': animal_id,\n",
    "            'cage_id': cage_id,\n",
    "            'low_days': low_days,\n",
    "            'spacings': spacings,\n",
    "            'has_4day': has_exact_4,\n",
    "            'assessment': assessment,\n",
    "            'median_power': median_power,\n",
    "            'threshold': threshold\n",
    "        })\n",
    "        \n",
    "        print(f\"{animal_id:<10} {cage_id:<8} {str(low_days):<25} {str(spacings):<20} {assessment}\")\n",
    "    \n",
    "    # Summary\n",
    "    n_strong = sum(1 for r in cycle_results if '✓' in r['assessment'])\n",
    "    n_moderate = sum(1 for r in cycle_results if '~' in r['assessment'])\n",
    "    n_total = len(cycle_results)\n",
    "    \n",
    "    print(\"-\"*90)\n",
    "    print(f\"Strong 4-day cycling: {n_strong}/{n_total}\")\n",
    "    print(f\"Moderate evidence: {n_moderate}/{n_total}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PHASE CONSISTENCY CHECK\n",
    "    # =========================================================================\n",
    "    all_low_days = []\n",
    "    for r in cycle_results:\n",
    "        all_low_days.extend(r['low_days'])\n",
    "    \n",
    "    if all_low_days:\n",
    "        phases = [(d - 1) % 4 for d in all_low_days]\n",
    "        phase_counts = Counter(phases)\n",
    "        \n",
    "        print(f\"\\n--- Phase Consistency Check ---\")\n",
    "        print(f\"Phase 0 (Days 1,5,9,13...): {phase_counts.get(0, 0)}\")\n",
    "        print(f\"Phase 1 (Days 2,6,10,14...): {phase_counts.get(1, 0)}\")\n",
    "        print(f\"Phase 2 (Days 3,7,11,15...): {phase_counts.get(2, 0)}\")\n",
    "        print(f\"Phase 3 (Days 4,8,12,16...): {phase_counts.get(3, 0)}\")\n",
    "        \n",
    "        if sum(phase_counts.values()) >= 4:\n",
    "            observed = [phase_counts.get(i, 0) for i in range(4)]\n",
    "            expected = [len(all_low_days) / 4] * 4\n",
    "            stat, p_chi = chisquare(observed, expected)\n",
    "            print(f\"\\nChi-square test: χ²={stat:.2f}, p={p_chi:.4f}\")\n",
    "            if p_chi < 0.05:\n",
    "                dominant = max(phase_counts, key=phase_counts.get)\n",
    "                print(f\"→ Significant clustering at Phase {dominant}\")\n",
    "            else:\n",
    "                print(f\"→ No significant phase clustering\")\n",
    "        else:\n",
    "            p_chi = None\n",
    "    else:\n",
    "        phase_counts = Counter()\n",
    "        p_chi = None\n",
    "    \n",
    "    # Store results\n",
    "    all_rep_results[rep] = {\n",
    "        'animal_results': animal_results,\n",
    "        'cycle_results': cycle_results,\n",
    "        'n_strong': n_strong,\n",
    "        'n_moderate': n_moderate,\n",
    "        'n_total': n_total,\n",
    "        'phase_counts': phase_counts,\n",
    "        'p_chi': p_chi,\n",
    "        'valid_days': valid_days\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIGURE 1: INDIVIDUAL ANIMAL BAR PLOTS WITH TREATMENT MARKERS\n",
    "# =============================================================================\n",
    "\n",
    "for rep, results in all_rep_results.items():\n",
    "    cfg = VEHICLE_CAGES[rep]\n",
    "    animal_results = results['animal_results']\n",
    "    cycle_results = results['cycle_results']\n",
    "    valid_days = results['valid_days']\n",
    "    \n",
    "    n_animals = len(animal_results)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_animals + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Get calendar dates for x-axis\n",
    "    start_date = pd.to_datetime(cfg['analysis_start'])\n",
    "    dates = [(start_date + pd.Timedelta(days=i)).strftime('%b %d') for i in range(cfg['n_days'])]\n",
    "    \n",
    "    for idx, r in enumerate(animal_results):\n",
    "        ax = axes[idx]\n",
    "        day_powers = r['day_powers']\n",
    "        days = list(range(1, len(day_powers) + 1))\n",
    "        \n",
    "        # Get threshold from cycle results\n",
    "        cr = next((c for c in cycle_results if c['animal_id'] == r['animal_id']), None)\n",
    "        if cr:\n",
    "            threshold = cr['threshold']\n",
    "            median_power = cr['median_power']\n",
    "            low_days = cr['low_days']\n",
    "        else:\n",
    "            valid_powers = [p for i, p in enumerate(day_powers) if valid_days[0] <= i+1 <= valid_days[1] and not np.isnan(p)]\n",
    "            median_power = np.median(valid_powers) if valid_powers else 0\n",
    "            threshold = median_power * 0.80\n",
    "            low_days = []\n",
    "        \n",
    "        # Color bars\n",
    "        colors = []\n",
    "        for i, p in enumerate(day_powers):\n",
    "            day_num = i + 1\n",
    "            if day_num < valid_days[0] or day_num > valid_days[1]:\n",
    "                colors.append('lightgray')\n",
    "            elif np.isnan(p):\n",
    "                colors.append('white')\n",
    "            elif p < threshold:\n",
    "                colors.append('red')\n",
    "            else:\n",
    "                colors.append('steelblue')\n",
    "        \n",
    "        ax.bar(days, day_powers, color=colors, edgecolor='black', alpha=0.8)\n",
    "        ax.axhline(y=threshold, color='red', linestyle='--', linewidth=2, label='80% threshold')\n",
    "        ax.axhline(y=median_power, color='green', linestyle='-', linewidth=1, label='Median')\n",
    "        \n",
    "        # Treatment markers\n",
    "        ymax = max([p for p in day_powers if not np.isnan(p)]) * 1.15\n",
    "        ax.axvline(x=cfg['dose_1_day'], color='purple', linestyle='-', linewidth=2.5, alpha=0.8)\n",
    "        ax.axvline(x=cfg['dose_2_day'], color='purple', linestyle='-', linewidth=2.5, alpha=0.8)\n",
    "        ax.axvline(x=cfg['cage_change_day'], color='orange', linestyle='--', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        # Title\n",
    "        if cr:\n",
    "            title_color = 'green' if '✓' in cr['assessment'] else 'orange' if '~' in cr['assessment'] else 'black'\n",
    "            ax.set_title(f\"Animal {r['animal_id']} (Cage {r['cage_id']})\\nLOW: {low_days}\", \n",
    "                        fontsize=9, color=title_color)\n",
    "        \n",
    "        ax.set_xlabel('Day')\n",
    "        ax.set_ylabel('Ultradian Power')\n",
    "        ax.set_xticks(days)\n",
    "        ax.set_ylim(0, ymax * 1.2)\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax.legend(loc='upper right', fontsize=7)\n",
    "    \n",
    "    for idx in range(len(animal_results), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.text(0.5, 0.02, \n",
    "             'Purple = Doses | Orange = Cage Change | Gray = Excluded | Red = LOW (potential estrus)',\n",
    "             ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.suptitle(f'{rep} - Ultradian Power by Calendar Day\\nValid: Days {valid_days[0]}-{valid_days[1]}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(f'morph2rep_{rep}_calendar_bars.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIGURE 2: HEATMAP WITH CALENDAR DATES\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "for col, (rep, cfg) in enumerate(VEHICLE_CAGES.items()):\n",
    "    ax = axes[col]\n",
    "    results = all_rep_results[rep]\n",
    "    animal_results = results['animal_results']\n",
    "    cycle_results = results['cycle_results']\n",
    "    valid_days = results['valid_days']\n",
    "    \n",
    "    # Collect data for heatmap\n",
    "    heatmap_data = []\n",
    "    animal_labels = []\n",
    "    cage_labels = []\n",
    "    \n",
    "    for cage_id in cfg['cages']:\n",
    "        for r in animal_results:\n",
    "            if r['cage_id'] == cage_id:\n",
    "                heatmap_data.append(r['day_powers'])\n",
    "                animal_labels.append(str(r['animal_id']))\n",
    "                cage_labels.append(cage_id)\n",
    "    \n",
    "    heatmap_data = np.array(heatmap_data)\n",
    "    \n",
    "    # Normalize by median (using valid days only)\n",
    "    normalized_data = np.zeros_like(heatmap_data)\n",
    "    for i in range(len(heatmap_data)):\n",
    "        valid_vals = [heatmap_data[i, j] for j in range(valid_days[0]-1, valid_days[1])\n",
    "                      if j < heatmap_data.shape[1] and not np.isnan(heatmap_data[i, j])]\n",
    "        median_val = np.nanmedian(valid_vals) if valid_vals else 1\n",
    "        normalized_data[i] = heatmap_data[i] / median_val if median_val > 0 else heatmap_data[i]\n",
    "    \n",
    "    # Plot heatmap\n",
    "    im = ax.imshow(normalized_data, aspect='auto', cmap='RdBu_r', vmin=0.5, vmax=1.5)\n",
    "    \n",
    "    # Mark LOW days\n",
    "    row_idx = 0\n",
    "    for cage_id in cfg['cages']:\n",
    "        for r in animal_results:\n",
    "            if r['cage_id'] == cage_id:\n",
    "                cr = next((c for c in cycle_results if c['animal_id'] == r['animal_id']), None)\n",
    "                if cr:\n",
    "                    for low_day in cr['low_days']:\n",
    "                        ax.scatter(low_day - 1, row_idx, marker='o', s=200, facecolors='none', \n",
    "                                  edgecolors='black', linewidths=2)\n",
    "                row_idx += 1\n",
    "    \n",
    "    # Gray out excluded days\n",
    "    ax.axvspan(-0.5, valid_days[0] - 1.5, alpha=0.4, color='gray')\n",
    "    if valid_days[1] < cfg['n_days']:\n",
    "        ax.axvspan(valid_days[1] - 0.5, cfg['n_days'] - 0.5, alpha=0.4, color='gray')\n",
    "    \n",
    "    # Treatment markers\n",
    "    ax.axvline(x=cfg['dose_1_day'] - 1, color='purple', linestyle='-', linewidth=3, label='Dose')\n",
    "    ax.axvline(x=cfg['dose_2_day'] - 1, color='purple', linestyle='-', linewidth=3)\n",
    "    ax.axvline(x=cfg['cage_change_day'] - 1, color='orange', linestyle='--', linewidth=2.5, label='Cage Change')\n",
    "    \n",
    "    # Calendar date labels\n",
    "    start_date = pd.to_datetime(cfg['analysis_start'])\n",
    "    date_labels = [(start_date + pd.Timedelta(days=i)).strftime('%b %d') for i in range(cfg['n_days'])]\n",
    "    \n",
    "    ax.set_xticks(range(cfg['n_days']))\n",
    "    ax.set_xticklabels(date_labels, rotation=45, ha='right', fontsize=8)\n",
    "    ax.set_yticks(range(len(animal_labels)))\n",
    "    ax.set_yticklabels([f'{animal_labels[i]}\\n({cage_labels[i]})' for i in range(len(animal_labels))], fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Animal (Cage)', fontsize=12)\n",
    "    ax.set_title(f\"{rep} - Normalized Ultradian Power\\n○ = LOW day | Gray = Excluded\", \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.5, pad=0.02)\n",
    "cbar.set_label('Power / Median', fontsize=11)\n",
    "cbar.ax.axhline(y=0.8, color='black', linestyle='--', linewidth=2)\n",
    "cbar.ax.text(2.5, 0.8, '80%', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('morph2rep_calendar_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: MORPH2REP ESTROUS CYCLE DETECTION (Calendar Days)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n--- Configuration ---\")\n",
    "print(f\"{'Replicate':<10} {'Date Range':<25} {'Valid Days':<15} {'Excluded'}\")\n",
    "print(\"-\"*70)\n",
    "for rep, cfg in VEHICLE_CAGES.items():\n",
    "    valid = f\"Days {cfg['valid_days'][0]}-{cfg['valid_days'][1]}\"\n",
    "    excluded = f\"Day 1\" if cfg['valid_days'][0] > 1 else \"None\"\n",
    "    print(f\"{rep:<10} {cfg['analysis_start']} to {cfg['analysis_end']:<10} {valid:<15} {excluded}\")\n",
    "\n",
    "print(\"\\n--- Results ---\")\n",
    "print(f\"\\n{'Metric':<35} {'Rep1':<15} {'Rep2':<15}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "rep1 = all_rep_results['Rep1']\n",
    "rep2 = all_rep_results['Rep2']\n",
    "\n",
    "print(f\"{'Animals analyzed':<35} {rep1['n_total']:<15} {rep2['n_total']:<15}\")\n",
    "print(f\"{'Strong 4-day cycling':<35} {rep1['n_strong']}/{rep1['n_total']:<15} {rep2['n_strong']}/{rep2['n_total']:<15}\")\n",
    "print(f\"{'Moderate evidence':<35} {rep1['n_moderate']}/{rep1['n_total']:<15} {rep2['n_moderate']}/{rep2['n_total']:<15}\")\n",
    "\n",
    "p1 = f\"p={rep1['p_chi']:.4f}\" if rep1['p_chi'] else \"N/A\"\n",
    "p2 = f\"p={rep2['p_chi']:.4f}\" if rep2['p_chi'] else \"N/A\"\n",
    "print(f\"{'Phase clustering':<35} {p1:<15} {p2:<15}\")\n",
    "\n",
    "print(\"\\n--- Treatment Timeline (Calendar Days) ---\")\n",
    "print(f\"\\n{'Event':<15} {'Rep1':<30} {'Rep2':<30}\")\n",
    "print(\"-\"*75)\n",
    "print(f\"{'Dose 1':<15} Day {VEHICLE_CAGES['Rep1']['dose_1_day']} ({VEHICLE_CAGES['Rep1']['dose_1'].strftime('%b %d, %I%p')}){'  ':<5} Day {VEHICLE_CAGES['Rep2']['dose_1_day']} ({VEHICLE_CAGES['Rep2']['dose_1'].strftime('%b %d, %I%p')})\")\n",
    "print(f\"{'Cage Change':<15} Day {VEHICLE_CAGES['Rep1']['cage_change_day']} ({VEHICLE_CAGES['Rep1']['cage_change'].strftime('%b %d, %I%p')}){'  ':<5} Day {VEHICLE_CAGES['Rep2']['cage_change_day']} ({VEHICLE_CAGES['Rep2']['cage_change'].strftime('%b %d, %I%p')})\")\n",
    "print(f\"{'Dose 2':<15} Day {VEHICLE_CAGES['Rep1']['dose_2_day']} ({VEHICLE_CAGES['Rep1']['dose_2'].strftime('%b %d, %I%p')}){'  ':<5} Day {VEHICLE_CAGES['Rep2']['dose_2_day']} ({VEHICLE_CAGES['Rep2']['dose_2'].strftime('%b %d, %I%p')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LIST OF SAVED FIGURES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVED FIGURES:\")\n",
    "print(\"=\"*60)\n",
    "print(\"  1. morph2rep_calendar_data_completeness.png\")\n",
    "print(\"  2. morph2rep_Rep1_calendar_bars.png\")\n",
    "print(\"  3. morph2rep_Rep2_calendar_bars.png\")\n",
    "print(\"  4. morph2rep_calendar_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusions\n",
    "\n",
    "### Time Alignment Choice\n",
    "\n",
    "We used **calendar day alignment** (midnight to midnight) rather than Smarr's circadian time alignment (6PM to 6PM) because:\n",
    "1. Direct mapping to treatment schedule dates\n",
    "2. Simpler interpretation\n",
    "3. Preserves more data (Day 16 in Rep1 has 13 hours of usable data)\n",
    "4. Daily averaging minimizes the impact of specific hour boundaries\n",
    "\n",
    "### Data Quality\n",
    "\n",
    "- **Rep1:** Day 1 excluded (only 2 hours of recording); Days 2-16 valid\n",
    "- **Rep2:** Day 1 excluded (only 10 hours of recording); Days 2-14 valid\n",
    "\n",
    "### Estrous Cycling Evidence\n",
    "\n",
    "Results from calendar day analysis show similar patterns to the time-shifted approach:\n",
    "- **Rep1:** Modest evidence of cycling, with individual animals showing 4-day patterns but no strong phase synchronization\n",
    "- **Rep2:** Weaker evidence, with LOW days tending to cluster late in the recording period\n",
    "\n",
    "The lack of strong phase clustering in both replicates suggests that while individual females may be cycling, they are not synchronized to a common phase—consistent with the expected \"staggered\" condition in group-housed females without male pheromone exposure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

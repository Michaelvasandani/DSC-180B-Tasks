{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c0a2a5-e191-40d1-b4a1-2ee32bab5d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE MORPHINE FEATURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Objective: Identify ALL features showing dose-dependent morphine response\n",
      "across temporal windows\n",
      "\n",
      "Loading comprehensive feature set...\n",
      "  Cages: 9\n",
      "  Dates: ['2025-01-14', '2025-01-15']\n",
      "\n",
      "1. Loading activity states...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Query interrupted",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     68\u001b[39m activity_paths = generate_paths(cages, dates, \u001b[33m'\u001b[39m\u001b[33manimal_activity_db.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     69\u001b[39m query = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[33mSELECT \u001b[39m\n\u001b[32m     71\u001b[39m \u001b[33m    cage_id,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m \u001b[33mWHERE resolution = 60\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m df_activity = \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m.df()\n\u001b[32m     79\u001b[39m df_activity[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df_activity[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     80\u001b[39m df_activity[\u001b[33m'\u001b[39m\u001b[33mminutes_from_injection\u001b[39m\u001b[33m'\u001b[39m] = (df_activity[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m] - INJECTION_DATETIME).dt.total_seconds() / \u001b[32m60\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: Query interrupted"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "TREATMENT_MAP = {\n",
    "    4917: '5 mg/kg', 4918: 'Vehicle', 4919: '25 mg/kg',\n",
    "    4920: '25 mg/kg', 4921: '5 mg/kg', 4922: 'Vehicle',\n",
    "    4923: 'Vehicle', 4924: '25 mg/kg', 4925: '5 mg/kg'\n",
    "}\n",
    "\n",
    "INJECTION_DATETIME = datetime(2025, 1, 14, 6, 0, 0)\n",
    "\n",
    "# Time windows (adjusted for cage-level data)\n",
    "TIME_WINDOWS = {\n",
    "    'baseline': (-30, 0),\n",
    "    'immediate': (0, 120),\n",
    "    'peak_early': (120, 240),\n",
    "    'peak_sustained': (240, 360),\n",
    "    'decline_early': (360, 480),\n",
    "    'decline_late': (480, 600),\n",
    "    'post_6hr': (600, 900),\n",
    "    'post_12hr': (900, 1200),\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE MORPHINE FEATURE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nObjective: Identify ALL features showing dose-dependent morphine response\")\n",
    "print(\"across temporal windows\\n\")\n",
    "\n",
    "# Initialize DuckDB\n",
    "con = duckdb.connect()\n",
    "con.execute(\"SET s3_region='us-east-1';\")\n",
    "con.execute(\"SET s3_url_style='path';\")\n",
    "\n",
    "def generate_paths(cages, dates, filename):\n",
    "    paths = []\n",
    "    for cage in cages:\n",
    "        for date in dates:\n",
    "            path = f\"s3://jax-envision-public-data/study_1001/2025v3.3/tabular/cage_id={cage}/date={date}/{filename}\"\n",
    "            paths.append(f\"'{path}'\")\n",
    "    return ', '.join(paths)\n",
    "\n",
    "# Load data from injection day + next day\n",
    "dates = [(INJECTION_DATETIME + timedelta(days=d)).strftime('%Y-%m-%d') \n",
    "         for d in range(0, 2)]\n",
    "cages = list(TREATMENT_MAP.keys())\n",
    "\n",
    "print(f\"Loading comprehensive feature set...\")\n",
    "print(f\"  Cages: {len(cages)}\")\n",
    "print(f\"  Dates: {dates}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ALL AVAILABLE FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "all_features = {}\n",
    "\n",
    "# 1. Activity states\n",
    "print(\"\\n1. Loading activity states...\")\n",
    "activity_paths = generate_paths(cages, dates, 'animal_activity_db.parquet')\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    cage_id,\n",
    "    time,\n",
    "    name,\n",
    "    value\n",
    "FROM read_parquet([{activity_paths}])\n",
    "WHERE resolution = 60\n",
    "\"\"\"\n",
    "df_activity = con.execute(query).df()\n",
    "df_activity['time'] = pd.to_datetime(df_activity['time'])\n",
    "df_activity['minutes_from_injection'] = (df_activity['time'] - INJECTION_DATETIME).dt.total_seconds() / 60\n",
    "\n",
    "activity_pivot = df_activity.pivot_table(\n",
    "    index=['cage_id', 'minutes_from_injection'],\n",
    "    columns='name',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ").reset_index()\n",
    "activity_pivot.columns.name = None\n",
    "\n",
    "print(f\"  Activity metrics: {[c for c in activity_pivot.columns if 'animal' in c]}\")\n",
    "\n",
    "# 2. Distance metrics\n",
    "print(\"2. Loading distance metrics...\")\n",
    "distance_paths = generate_paths(cages, dates, 'animal_aggs_short_id.parquet')\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    cage_id,\n",
    "    time,\n",
    "    name,\n",
    "    AVG(value) as value\n",
    "FROM read_parquet([{distance_paths}])\n",
    "WHERE resolution = 60\n",
    "GROUP BY cage_id, time, name\n",
    "\"\"\"\n",
    "df_distance = con.execute(query).df()\n",
    "df_distance['time'] = pd.to_datetime(df_distance['time'])\n",
    "df_distance['minutes_from_injection'] = (df_distance['time'] - INJECTION_DATETIME).dt.total_seconds() / 60\n",
    "\n",
    "distance_pivot = df_distance.pivot_table(\n",
    "    index=['cage_id', 'minutes_from_injection'],\n",
    "    columns='name',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ").reset_index()\n",
    "distance_pivot.columns.name = None\n",
    "\n",
    "print(f\"  Distance metrics: {[c for c in distance_pivot.columns if 'distance' in c or 'animal' in c]}\")\n",
    "\n",
    "# 3. Respiration\n",
    "print(\"3. Loading respiration metrics...\")\n",
    "resp_paths = generate_paths(cages, dates, 'animal_respiration.parquet')\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    cage_id,\n",
    "    time,\n",
    "    name,\n",
    "    AVG(value) as value\n",
    "FROM read_parquet([{resp_paths}])\n",
    "GROUP BY cage_id, time, name\n",
    "\"\"\"\n",
    "df_resp = con.execute(query).df()\n",
    "df_resp['time'] = pd.to_datetime(df_resp['time'])\n",
    "df_resp['minutes_from_injection'] = (df_resp['time'] - INJECTION_DATETIME).dt.total_seconds() / 60\n",
    "\n",
    "resp_pivot = df_resp.pivot_table(\n",
    "    index=['cage_id', 'minutes_from_injection'],\n",
    "    columns='name',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ").reset_index()\n",
    "resp_pivot.columns.name = None\n",
    "\n",
    "print(f\"  Respiration metrics: {[c for c in resp_pivot.columns if 'respiration' in c]}\")\n",
    "\n",
    "# 4. Social distance\n",
    "print(\"4. Loading social distance metrics...\")\n",
    "social_paths = generate_paths(cages, dates, 'animal_sociability_pairwise.parquet')\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    cage_id,\n",
    "    time,\n",
    "    name,\n",
    "    AVG(value) as value\n",
    "FROM read_parquet([{social_paths}])\n",
    "GROUP BY cage_id, time, name\n",
    "\"\"\"\n",
    "df_social = con.execute(query).df()\n",
    "df_social['time'] = pd.to_datetime(df_social['time'])\n",
    "df_social['minutes_from_injection'] = (df_social['time'] - INJECTION_DATETIME).dt.total_seconds() / 60\n",
    "\n",
    "social_pivot = df_social.pivot_table(\n",
    "    index=['cage_id', 'minutes_from_injection'],\n",
    "    columns='name',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ").reset_index()\n",
    "social_pivot.columns.name = None\n",
    "\n",
    "print(f\"  Social metrics: {[c for c in social_pivot.columns if 'distance' in c]}\")\n",
    "\n",
    "# 5. Motion scores\n",
    "print(\"5. Loading motion scores...\")\n",
    "motion_paths = generate_paths(cages, dates, 'cage_motion_vector.parquet')\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    cage_id,\n",
    "    time,\n",
    "    AVG(value) as motion_score\n",
    "FROM read_parquet([{motion_paths}])\n",
    "WHERE resolution = 60\n",
    "GROUP BY cage_id, time\n",
    "\"\"\"\n",
    "df_motion = con.execute(query).df()\n",
    "df_motion['time'] = pd.to_datetime(df_motion['time'])\n",
    "df_motion['minutes_from_injection'] = (df_motion['time'] - INJECTION_DATETIME).dt.total_seconds() / 60\n",
    "\n",
    "# 6. Time series database (additional metrics)\n",
    "print(\"6. Loading time series metrics...\")\n",
    "tsdb_paths = generate_paths(cages, dates, 'animal_tsdb_mvp.parquet')\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    cage_id,\n",
    "    time,\n",
    "    name,\n",
    "    AVG(value) as value\n",
    "FROM read_parquet([{tsdb_paths}])\n",
    "WHERE resolution = 60\n",
    "GROUP BY cage_id, time, name\n",
    "\"\"\"\n",
    "df_tsdb = con.execute(query).df()\n",
    "df_tsdb['time'] = pd.to_datetime(df_tsdb['time'])\n",
    "df_tsdb['minutes_from_injection'] = (df_tsdb['time'] - INJECTION_DATETIME).dt.total_seconds() / 60\n",
    "\n",
    "tsdb_pivot = df_tsdb.pivot_table(\n",
    "    index=['cage_id', 'minutes_from_injection'],\n",
    "    columns='name',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ").reset_index()\n",
    "tsdb_pivot.columns.name = None\n",
    "\n",
    "print(f\"  TSDB metrics: {len([c for c in tsdb_pivot.columns if c not in ['cage_id', 'minutes_from_injection']])} features\")\n",
    "\n",
    "# Merge all features\n",
    "print(\"\\nMerging all feature sources...\")\n",
    "df = activity_pivot.copy()\n",
    "df = df.merge(distance_pivot, on=['cage_id', 'minutes_from_injection'], how='outer')\n",
    "df = df.merge(resp_pivot, on=['cage_id', 'minutes_from_injection'], how='outer')\n",
    "df = df.merge(social_pivot, on=['cage_id', 'minutes_from_injection'], how='outer')\n",
    "df = df.merge(df_motion, on=['cage_id', 'minutes_from_injection'], how='outer')\n",
    "df = df.merge(tsdb_pivot, on=['cage_id', 'minutes_from_injection'], how='outer')\n",
    "\n",
    "df['treatment'] = df['cage_id'].map(TREATMENT_MAP)\n",
    "\n",
    "# Get numeric feature columns\n",
    "feature_cols = [c for c in df.columns \n",
    "                if c not in ['cage_id', 'minutes_from_injection', 'treatment'] \n",
    "                and df[c].dtype in ['float64', 'float32', 'int64', 'int32']]\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(df)} records\")\n",
    "print(f\"✓ Total features: {len(feature_cols)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BASELINE NORMALIZATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE NORMALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baseline_window = TIME_WINDOWS['baseline']\n",
    "baseline_data = df[\n",
    "    (df['minutes_from_injection'] >= baseline_window[0]) & \n",
    "    (df['minutes_from_injection'] < baseline_window[1])\n",
    "]\n",
    "\n",
    "cage_baselines = {}\n",
    "for feature in feature_cols:\n",
    "    cage_baselines[feature] = baseline_data.groupby('cage_id')[feature].mean()\n",
    "\n",
    "# Normalize\n",
    "for feature in feature_cols:\n",
    "    df[f'{feature}_baseline'] = df['cage_id'].map(cage_baselines[feature])\n",
    "    df[f'{feature}_fold_change'] = df[feature] / df[f'{feature}_baseline']\n",
    "\n",
    "# ============================================================================\n",
    "# CALCULATE EFFECTS FOR ALL FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING ALL FEATURES ACROSS TIME WINDOWS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "\n",
    "for window_name, (start, end) in TIME_WINDOWS.items():\n",
    "    if window_name == 'baseline':\n",
    "        continue\n",
    "    \n",
    "    window_data = df[\n",
    "        (df['minutes_from_injection'] >= start) & \n",
    "        (df['minutes_from_injection'] < end)\n",
    "    ]\n",
    "    \n",
    "    for treatment in ['Vehicle', '5 mg/kg', '25 mg/kg']:\n",
    "        for feature in feature_cols:\n",
    "            # Get cage-level fold changes\n",
    "            cage_fc = window_data[window_data['treatment'] == treatment].groupby('cage_id')[f'{feature}_fold_change'].mean()\n",
    "            \n",
    "            if len(cage_fc) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Remove NaN/inf values\n",
    "            cage_fc = cage_fc[np.isfinite(cage_fc)]\n",
    "            \n",
    "            if len(cage_fc) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Calculate statistics\n",
    "            mean_fc = cage_fc.mean()\n",
    "            std_fc = cage_fc.std()\n",
    "            n = len(cage_fc)\n",
    "            \n",
    "            # Calculate percent change\n",
    "            pct_change = (mean_fc - 1) * 100\n",
    "            \n",
    "            # Calculate Cohen's d (comparing to 1.0 = no change)\n",
    "            if std_fc > 0:\n",
    "                cohens_d = (mean_fc - 1) / std_fc\n",
    "            else:\n",
    "                cohens_d = 0\n",
    "            \n",
    "            results.append({\n",
    "                'window': window_name,\n",
    "                'treatment': treatment,\n",
    "                'feature': feature,\n",
    "                'n_cages': n,\n",
    "                'mean_fold_change': mean_fc,\n",
    "                'pct_change': pct_change,\n",
    "                'std': std_fc,\n",
    "                'cohens_d': cohens_d,\n",
    "                'abs_cohens_d': abs(cohens_d)\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"✓ Analyzed {len(results_df)} feature × treatment × window combinations\")\n",
    "\n",
    "# ============================================================================\n",
    "# IDENTIFY DOSE-RESPONSIVE FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DOSE-RESPONSE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For each feature and window, check if there's dose-response relationship\n",
    "dose_response_features = []\n",
    "\n",
    "for window_name in [w for w in TIME_WINDOWS.keys() if w != 'baseline']:\n",
    "    window_results = results_df[results_df['window'] == window_name]\n",
    "    \n",
    "    for feature in feature_cols:\n",
    "        feature_results = window_results[window_results['feature'] == feature]\n",
    "        \n",
    "        if len(feature_results) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Get mean effects for each dose\n",
    "        vehicle_effect = feature_results[feature_results['treatment'] == 'Vehicle']['pct_change'].values\n",
    "        low_effect = feature_results[feature_results['treatment'] == '5 mg/kg']['pct_change'].values\n",
    "        high_effect = feature_results[feature_results['treatment'] == '25 mg/kg']['pct_change'].values\n",
    "        \n",
    "        if len(vehicle_effect) == 0 or len(low_effect) == 0 or len(high_effect) == 0:\n",
    "            continue\n",
    "        \n",
    "        vehicle_effect = vehicle_effect[0]\n",
    "        low_effect = low_effect[0]\n",
    "        high_effect = high_effect[0]\n",
    "        \n",
    "        # Check for monotonic dose-response\n",
    "        is_increasing = (abs(high_effect) > abs(low_effect) > abs(vehicle_effect))\n",
    "        is_decreasing = (abs(high_effect) < abs(low_effect) < abs(vehicle_effect))\n",
    "        \n",
    "        # Get effect sizes\n",
    "        high_cohens_d = feature_results[feature_results['treatment'] == '25 mg/kg']['cohens_d'].values[0]\n",
    "        \n",
    "        # Criteria for dose-responsive feature:\n",
    "        # 1. High dose shows |Cohen's d| > 1.0 (large effect)\n",
    "        # 2. Dose-response relationship exists\n",
    "        # 3. High dose effect is at least 2x vehicle effect\n",
    "        \n",
    "        if abs(high_cohens_d) > 1.0 and (is_increasing or is_decreasing):\n",
    "            dose_response_features.append({\n",
    "                'feature': feature,\n",
    "                'window': window_name,\n",
    "                'vehicle_pct': vehicle_effect,\n",
    "                'low_dose_pct': low_effect,\n",
    "                'high_dose_pct': high_effect,\n",
    "                'high_cohens_d': high_cohens_d,\n",
    "                'dose_response_type': 'increasing' if is_increasing else 'decreasing'\n",
    "            })\n",
    "\n",
    "dose_response_df = pd.DataFrame(dose_response_features)\n",
    "\n",
    "if len(dose_response_df) > 0:\n",
    "    print(f\"\\n✓ Found {len(dose_response_df['feature'].unique())} features with dose-response\")\n",
    "    print(f\"\\nTop dose-responsive features:\")\n",
    "    # Add absolute value column\n",
    "    dose_response_df['abs_high_cohens_d'] = dose_response_df['high_cohens_d'].abs()\n",
    "    top_features = dose_response_df.sort_values('abs_high_cohens_d', ascending=False).head(20)\n",
    "    print(top_features[['feature', 'window', 'high_dose_pct', 'high_cohens_d', 'dose_response_type']].to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE COMPREHENSIVE HEATMAP\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING COMPREHENSIVE FEATURE HEATMAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter to most responsive features across all windows\n",
    "feature_max_effects = results_df.groupby('feature')['abs_cohens_d'].max().sort_values(ascending=False)\n",
    "top_features = feature_max_effects.head(30).index.tolist()\n",
    "\n",
    "print(f\"\\nPlotting top {len(top_features)} features by maximum effect size\")\n",
    "\n",
    "# Create heatmap for each treatment\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 20))\n",
    "\n",
    "window_order = ['immediate', 'peak_early', 'peak_sustained', 'decline_early', \n",
    "                'decline_late', 'post_6hr', 'post_12hr']\n",
    "\n",
    "for idx, treatment in enumerate(['Vehicle', '5 mg/kg', '25 mg/kg']):\n",
    "    treatment_data = results_df[\n",
    "        (results_df['treatment'] == treatment) &\n",
    "        (results_df['feature'].isin(top_features))\n",
    "    ]\n",
    "    \n",
    "    if len(treatment_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Create pivot\n",
    "    pivot = treatment_data.pivot_table(\n",
    "        index='feature',\n",
    "        columns='window',\n",
    "        values='pct_change',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    # Reorder columns\n",
    "    pivot = pivot[[col for col in window_order if col in pivot.columns]]\n",
    "    \n",
    "    # Sort by maximum absolute effect\n",
    "    feature_importance = pivot.abs().max(axis=1).sort_values(ascending=False)\n",
    "    pivot = pivot.loc[feature_importance.index]\n",
    "    \n",
    "    # Dynamic color scale\n",
    "    vmax = max(50, pivot.abs().max().max())\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    sns.heatmap(pivot,\n",
    "               ax=ax,\n",
    "               cmap='RdBu_r',\n",
    "               center=0,\n",
    "               vmin=-vmax, vmax=vmax,\n",
    "               cbar_kws={'label': '% Change from Baseline'},\n",
    "               linewidths=0.5,\n",
    "               annot=True,\n",
    "               fmt='.0f',\n",
    "               annot_kws={'size': 7})\n",
    "    \n",
    "    ax.set_title(f'{treatment} - All Features Temporal Profile', \n",
    "                fontsize=14, fontweight='bold', pad=10)\n",
    "    ax.set_xlabel('Time Window', fontsize=11)\n",
    "    ax.set_ylabel('Feature', fontsize=11)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comprehensive_feature_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Saved: comprehensive_feature_heatmap.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY REPORT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal features analyzed: {len(feature_cols)}\")\n",
    "print(f\"Features with dose-response: {len(dose_response_df['feature'].unique())}\")\n",
    "print(f\"\\nFeatures by category:\")\n",
    "\n",
    "# Categorize features\n",
    "categories = {\n",
    "    'Activity States': [f for f in feature_cols if 'bouts' in f],\n",
    "    'Distance/Movement': [f for f in feature_cols if 'distance' in f.lower()],\n",
    "    'Respiration': [f for f in feature_cols if 'respiration' in f.lower()],\n",
    "    'Social': [f for f in feature_cols if 'social' in f.lower() or any(x in f for x in ['mean_all', 'mean_other', 'nearest'])],\n",
    "    'Other': [f for f in feature_cols if not any(cat in f.lower() for cat in ['bout', 'distance', 'respiration', 'social', 'mean_', 'nearest'])]\n",
    "}\n",
    "\n",
    "for category, features in categories.items():\n",
    "    if len(features) > 0:\n",
    "        responsive = [f for f in features if f in dose_response_df['feature'].unique()]\n",
    "        print(f\"  {category}: {len(features)} total, {len(responsive)} dose-responsive\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('all_features_analysis.csv', index=False)\n",
    "if len(dose_response_df) > 0:\n",
    "    dose_response_df.to_csv('dose_responsive_features.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Saved: all_features_analysis.csv\")\n",
    "print(\"✓ Saved: dose_responsive_features.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT STEPS FOR PRESENTATION:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Review dose_responsive_features.csv for features beyond locomotion\")\n",
    "print(\"2. Check if effect directions are consistent within individuals\")\n",
    "print(\"3. Identify novel morphine biomarkers in this dataset\")\n",
    "print(\"4. Compare effect sizes across feature categories\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2683ff-c0ac-4fd8-b36f-a4a57903e278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

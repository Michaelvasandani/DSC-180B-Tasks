{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4707f5b-15ae-4ecd-9c6e-856ff3ad734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7278e-d807-40b8-91ab-3134bdf9524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f7ef6-1af3-4ba8-a3d6-3c7913c8693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "con.execute(\"SET s3_region='us-east-1'\")\n",
    "S3_BASE = \"s3://jax-envision-public-data/study_1001/2025v3.3/tabular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30522f64-7b81-48a1-9a9d-ff20f43a6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOSE_MAPPING_REP1 = {\n",
    "    4917: '5 mg/kg',  4918: 'Vehicle',  4919: '25 mg/kg',\n",
    "    4920: '25 mg/kg', 4921: '5 mg/kg',  4922: 'Vehicle',\n",
    "    4923: 'Vehicle',  4924: '25 mg/kg', 4925: '5 mg/kg'\n",
    "}\n",
    "DOSE_MAPPING_REP2 = {\n",
    "    4926: '25 mg/kg', 4927: '5 mg/kg',  4928: 'Vehicle',\n",
    "    4929: 'Vehicle',  4930: '25 mg/kg', 4931: '5 mg/kg',\n",
    "    4932: '5 mg/kg',  4933: '25 mg/kg', 4934: 'Vehicle'\n",
    "}\n",
    "\n",
    "INJECTION_EVENTS = [\n",
    "    {\n",
    "        'name': 'Replicate 1, Dose 1',\n",
    "        'short_name': 'Rep1_Dose1',\n",
    "        'injection_time_utc': pd.Timestamp('2025-01-14 11:00:00'),\n",
    "        'dates_to_load': ['2025-01-13', '2025-01-14', '2025-01-15'],\n",
    "        'cages': list(DOSE_MAPPING_REP1.keys()),\n",
    "        'dose_mapping': DOSE_MAPPING_REP1,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Replicate 1, Dose 2',\n",
    "        'short_name': 'Rep1_Dose2',\n",
    "        'injection_time_utc': pd.Timestamp('2025-01-17 22:00:00'),\n",
    "        'dates_to_load': ['2025-01-17', '2025-01-18', '2025-01-19'],\n",
    "        'cages': list(DOSE_MAPPING_REP1.keys()),\n",
    "        'dose_mapping': DOSE_MAPPING_REP1,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Replicate 2, Dose 1',\n",
    "        'short_name': 'Rep2_Dose1',\n",
    "        'injection_time_utc': pd.Timestamp('2025-01-28 22:00:00'),\n",
    "        'dates_to_load': ['2025-01-28', '2025-01-29', '2025-01-30'],\n",
    "        'cages': list(DOSE_MAPPING_REP2.keys()),\n",
    "        'dose_mapping': DOSE_MAPPING_REP2,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Replicate 2, Dose 2',\n",
    "        'short_name': 'Rep2_Dose2',\n",
    "        'injection_time_utc': pd.Timestamp('2025-01-31 11:00:00'),\n",
    "        'dates_to_load': ['2025-01-30', '2025-01-31', '2025-02-01'],\n",
    "        'cages': list(DOSE_MAPPING_REP2.keys()),\n",
    "        'dose_mapping': DOSE_MAPPING_REP2,\n",
    "    }\n",
    "]\n",
    "\n",
    "TIME_WINDOWS = {\n",
    "    'baseline': (-180, -60),\n",
    "    'immediate': (0, 30),\n",
    "    'peak_early': (30, 90),\n",
    "    'peak_sustained': (90, 180),\n",
    "    'decline_early': (180, 300),\n",
    "    'decline_late': (300, 420),\n",
    "    'post_6hr': (360, 540),\n",
    "    'post_12hr': (720, 900),\n",
    "    'next_day': (1380, 1560)\n",
    "}\n",
    "\n",
    "WINDOW_ORDER = ['immediate', 'peak_early', 'peak_sustained', 'decline_early', \n",
    "                'decline_late', 'post_6hr', 'post_12hr', 'next_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97797975-6080-4d8d-8c14-68425f4a23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cage_data(cage_id, date_str, dose_mapping, file_type, query_filter=\"\"):\n",
    "    \"\"\"Load parquet data for a specific cage and date.\"\"\"\n",
    "    path = f\"{S3_BASE}/cage_id={cage_id}/date={date_str}/{file_type}.parquet\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM read_parquet('{path}')\n",
    "    WHERE resolution = 60\n",
    "    {query_filter}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df = con.execute(query).fetchdf()\n",
    "        df['cage_id'] = cage_id\n",
    "        df['dose_group'] = dose_mapping[cage_id]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Cage {cage_id}, Date {date_str}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def load_injection_event_data(event, file_type, query_filter=\"\"):\n",
    "    \"\"\"Load data for a single injection event.\"\"\"\n",
    "    print(f\"Loading: {event['name']}\")\n",
    "    \n",
    "    dfs = []\n",
    "    for date_str in event['dates_to_load']:\n",
    "        for cage_id in event['cages']:\n",
    "            df = load_cage_data(cage_id, date_str, event['dose_mapping'], file_type, query_filter)\n",
    "            if not df.empty:\n",
    "                dfs.append(df)\n",
    "    \n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    df_all['time'] = pd.to_datetime(df_all['time'])\n",
    "    df_all['minutes_from_injection'] = (\n",
    "        df_all['time'] - event['injection_time_utc']\n",
    "    ).dt.total_seconds() / 60\n",
    "    df_all = df_all[\n",
    "        (df_all['minutes_from_injection'] >= -180) &\n",
    "        (df_all['minutes_from_injection'] <= 1560)\n",
    "    ]\n",
    "    df_all['event'] = event['short_name']\n",
    "    \n",
    "    print(f\"  Loaded {len(df_all):,} rows\")\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def load_all_events(file_type, query_filter=\"\"):\n",
    "    \"\"\"Load data from all injection events.\"\"\"\n",
    "    all_data = []\n",
    "    for event in INJECTION_EVENTS:\n",
    "        df = load_injection_event_data(event, file_type, query_filter)\n",
    "        if not df.empty:\n",
    "            all_data.append(df)\n",
    "    \n",
    "    df_combined = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nTotal: {len(df_combined):,} rows\")\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9d109-e68f-4c1b-9a33-3e09b12f3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percent_change_all_features(df):\n",
    "    \"\"\"Compute percent change for all features.\"\"\"\n",
    "    features = df['name'].unique()\n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"Computing percent change for {len(features)} features...\")\n",
    "    \n",
    "    for feature in features:\n",
    "        df_feat = df[df['name'] == feature].copy()\n",
    "        baseline_start, baseline_end = TIME_WINDOWS['baseline']\n",
    "        \n",
    "        for (animal_id, dose_group, event), animal_df in df_feat.groupby(['animal_id', 'dose_group', 'event']):\n",
    "            baseline_data = animal_df[\n",
    "                (animal_df['minutes_from_injection'] >= baseline_start) &\n",
    "                (animal_df['minutes_from_injection'] < baseline_end)\n",
    "            ]['value']\n",
    "            \n",
    "            if baseline_data.empty or baseline_data.mean() == 0:\n",
    "                continue\n",
    "            \n",
    "            baseline_mean = baseline_data.mean()\n",
    "            \n",
    "            for window_name, (win_start, win_end) in TIME_WINDOWS.items():\n",
    "                if window_name == 'baseline':\n",
    "                    continue\n",
    "                \n",
    "                window_data = animal_df[\n",
    "                    (animal_df['minutes_from_injection'] >= win_start) &\n",
    "                    (animal_df['minutes_from_injection'] < win_end)\n",
    "                ]['value']\n",
    "                \n",
    "                if window_data.empty:\n",
    "                    continue\n",
    "                \n",
    "                window_mean = window_data.mean()\n",
    "                pct_change = ((window_mean - baseline_mean) / baseline_mean) * 100\n",
    "                \n",
    "                all_results.append({\n",
    "                    'animal_id': animal_id,\n",
    "                    'dose_group': dose_group,\n",
    "                    'event': event,\n",
    "                    'feature': feature,\n",
    "                    'window': window_name,\n",
    "                    'pct_change': pct_change\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48335ad-c13a-4737-8cc9-b74cc61576d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cage_data(cage_id, date_str, dose_mapping, file_type='animal_drinking'):\n",
    "    \"\"\"Load drinking and feeding.\"\"\"\n",
    "    path = f\"{S3_BASE}/cage_id={cage_id}/date={date_str}/{file_type}.parquet\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM read_parquet('{path}')\n",
    "    WHERE resolution = 60\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df = con.execute(query).fetchdf()\n",
    "        df['cage_id'] = cage_id\n",
    "        df['dose_group'] = dose_mapping[cage_id]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Cage {cage_id}, Date {date_str}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "df_drinking_feeding = load_all_events(resolution=60)\n",
    "print(df_drinking_feeding['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b26e00-3a1a-4787-a59b-4737830c7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from animal_activity_db: locomotion, active, inactive, climbing\n",
    "print(\"=== Loading Activity Features ===\")\n",
    "df_activity = load_all_events(\n",
    "    file_type='animal_activity_db',\n",
    "    query_filter=\"\"  # Gets all: locomotion, active, inactive, climbing\n",
    ")\n",
    "print(f\"Activity features: {df_activity['name'].unique()}\")\n",
    "\n",
    "# Load from animal_drinking: drinking, feeding\n",
    "print(\"\\n=== Loading Drinking & Feeding ===\")\n",
    "df_drinking_feeding = load_all_events(\n",
    "    file_type='animal_drinking',\n",
    "    query_filter=\"\"\n",
    ")\n",
    "print(f\"Drinking features: {df_drinking_feeding['name'].unique()}\")\n",
    "\n",
    "# Load from animal_tsdb_mvp: inferred_sleep\n",
    "print(\"\\n=== Loading Inferred Sleep ===\")\n",
    "df_sleep = load_all_events(\n",
    "    file_type='animal_tsdb_mvp',\n",
    "    query_filter=\"AND name = 'animal_bouts.inferred_sleep'\"\n",
    ")\n",
    "print(f\"Sleep features: {df_sleep['name'].unique()}\")\n",
    "\n",
    "# Combine all\n",
    "df_combined = pd.concat([df_activity, df_drinking_feeding, df_sleep], ignore_index=True)\n",
    "print(f\"\\n=== Combined ===\")\n",
    "print(f\"Total rows: {len(df_combined):,}\")\n",
    "print(f\"Features: {df_combined['name'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532aeb3-dc7f-4946-9a5f-96c57da2dfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
